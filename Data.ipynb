{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "572fca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score\n",
    "import xgboost as xgb\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c6ea61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.Config.set_tbl_rows(50)\n",
    "pl.Config.set_fmt_str_lengths(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7e5b1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths - adjust these to your actual paths\n",
    "DATA_DIR = Path(\"./data\")  # Change to your data directory\n",
    "SALES_FILE = DATA_DIR / \"valio_aimo_sales_and_deliveries_junction_2025.csv\"\n",
    "PURCHASES_FILE = DATA_DIR / \"valio_aimo_purchases_junction_2025.csv\"\n",
    "PRODUCT_FILE = DATA_DIR / \"valio_aimo_product_data_junction_2025.json\"\n",
    "REPLACEMENT_FILE = DATA_DIR / \"valio_aimo_replacement_orders_junction_2025.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eea1058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales & Deliveries shape: (7357509, 18)\n",
      "shape: (5, 18)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ order_num ┆ order_cre ┆ order_cre ┆ requested ┆ … ┆ warehouse ┆ picking_c ┆ picking_c ┆ picking_ │\n",
      "│ ber       ┆ ated_date ┆ ated_time ┆ _delivery ┆   ┆ _number   ┆ onfirmed_ ┆ onfirmed_ ┆ picked_q │\n",
      "│ ---       ┆ ---       ┆ ---       ┆ _date     ┆   ┆ ---       ┆ date      ┆ time      ┆ ty       │\n",
      "│ i64       ┆ str       ┆ i64       ┆ ---       ┆   ┆ i64       ┆ ---       ┆ ---       ┆ ---      │\n",
      "│           ┆           ┆           ┆ str       ┆   ┆           ┆ str       ┆ i64       ┆ f64      │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 10000000  ┆ 2024-09-0 ┆ 336       ┆ 2024-09-0 ┆ … ┆ 3001      ┆ 2024-09-0 ┆ 203837    ┆ 5.0      │\n",
      "│           ┆ 1         ┆           ┆ 2         ┆   ┆           ┆ 1         ┆           ┆          │\n",
      "│ 10000000  ┆ 2024-09-0 ┆ 336       ┆ 2024-09-0 ┆ … ┆ 3001      ┆ 2024-09-0 ┆ 203734    ┆ 12.0     │\n",
      "│           ┆ 1         ┆           ┆ 2         ┆   ┆           ┆ 1         ┆           ┆          │\n",
      "│ 10000000  ┆ 2024-09-0 ┆ 336       ┆ 2024-09-0 ┆ … ┆ 3001      ┆ 2024-09-0 ┆ 204149    ┆ 4.0      │\n",
      "│           ┆ 1         ┆           ┆ 2         ┆   ┆           ┆ 1         ┆           ┆          │\n",
      "│ 10000000  ┆ 2024-09-0 ┆ 336       ┆ 2024-09-0 ┆ … ┆ 3001      ┆ 2024-09-0 ┆ 204124    ┆ 4.0      │\n",
      "│           ┆ 1         ┆           ┆ 2         ┆   ┆           ┆ 1         ┆           ┆          │\n",
      "│ 10000000  ┆ 2024-09-0 ┆ 336       ┆ 2024-09-0 ┆ … ┆ 3001      ┆ 2024-09-0 ┆ 205255    ┆ 8.0      │\n",
      "│           ┆ 1         ┆           ┆ 2         ┆   ┆           ┆ 1         ┆           ┆          │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n",
      "\n",
      "Purchases shape: (782783, 11)\n",
      "shape: (5, 11)\n",
      "┌────────────┬────────────┬────────────┬────────────┬───┬───────────┬───────────┬──────┬───────────┐\n",
      "│ order_numb ┆ po_row_num ┆ customer_n ┆ po_created ┆ … ┆ storage_l ┆ ordered_q ┆ unit ┆ received_ │\n",
      "│ er         ┆ ber        ┆ umber      ┆ _date      ┆   ┆ ocation   ┆ ty        ┆ ---  ┆ qty       │\n",
      "│ ---        ┆ ---        ┆ ---        ┆ ---        ┆   ┆ ---       ┆ ---       ┆ str  ┆ ---       │\n",
      "│ i64        ┆ i64        ┆ i64        ┆ str        ┆   ┆ i64       ┆ f64       ┆      ┆ f64       │\n",
      "╞════════════╪════════════╪════════════╪════════════╪═══╪═══════════╪═══════════╪══════╪═══════════╡\n",
      "│ 2300000000 ┆ 10         ┆ 30386      ┆ 2024-09-01 ┆ … ┆ 2011      ┆ 8.0       ┆ ST   ┆ 8.0       │\n",
      "│ 2300000001 ┆ 10         ┆ 30386      ┆ 2024-09-01 ┆ … ┆ 2011      ┆ 3.0       ┆ ST   ┆ 3.0       │\n",
      "│ 2300000002 ┆ 10         ┆ 30386      ┆ 2024-09-01 ┆ … ┆ 2011      ┆ 4.0       ┆ ST   ┆ 4.0       │\n",
      "│ 2300000002 ┆ 20         ┆ 30386      ┆ 2024-09-01 ┆ … ┆ 2011      ┆ 4.0       ┆ ST   ┆ 4.0       │\n",
      "│ 2300000003 ┆ 10         ┆ 30386      ┆ 2024-09-01 ┆ … ┆ 2011      ┆ 4.0       ┆ RAS  ┆ 4.0       │\n",
      "└────────────┴────────────┴────────────┴────────────┴───┴───────────┴───────────┴──────┴───────────┘\n",
      "\n",
      "Replacements shape: (15069, 18)\n",
      "shape: (5, 18)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ order_num ┆ order_cre ┆ order_cre ┆ requested ┆ … ┆ warehouse ┆ picking_c ┆ picking_c ┆ picking_ │\n",
      "│ ber       ┆ ated_date ┆ ated_time ┆ _delivery ┆   ┆ _number   ┆ onfirmed_ ┆ onfirmed_ ┆ picked_q │\n",
      "│ ---       ┆ ---       ┆ ---       ┆ _date     ┆   ┆ ---       ┆ date      ┆ time      ┆ ty       │\n",
      "│ i64       ┆ str       ┆ i64       ┆ ---       ┆   ┆ i64       ┆ ---       ┆ ---       ┆ ---      │\n",
      "│           ┆           ┆           ┆ str       ┆   ┆           ┆ str       ┆ i64       ┆ f64      │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 32014535  ┆ 2024-09-0 ┆ 70832     ┆ 2024-09-0 ┆ … ┆ 3001      ┆ 2024-09-0 ┆ 82024     ┆ 2.0      │\n",
      "│           ┆ 2         ┆           ┆ 2         ┆   ┆           ┆ 2         ┆           ┆          │\n",
      "│ 32014536  ┆ 2024-09-0 ┆ 70818     ┆ 2024-09-0 ┆ … ┆ 3001      ┆ 2024-09-0 ┆ 81259     ┆ 1.0      │\n",
      "│           ┆ 2         ┆           ┆ 2         ┆   ┆           ┆ 2         ┆           ┆          │\n",
      "│ 32014537  ┆ 2024-09-0 ┆ 71137     ┆ 2024-09-0 ┆ … ┆ 3001      ┆ 2024-09-0 ┆ 74027     ┆ 5.0      │\n",
      "│           ┆ 2         ┆           ┆ 2         ┆   ┆           ┆ 2         ┆           ┆          │\n",
      "│ 32014538  ┆ 2024-09-0 ┆ 71223     ┆ 2024-09-0 ┆ … ┆ 3001      ┆ 2024-09-0 ┆ 81532     ┆ 1.0      │\n",
      "│           ┆ 2         ┆           ┆ 2         ┆   ┆           ┆ 2         ┆           ┆          │\n",
      "│ 32014539  ┆ 2024-09-0 ┆ 71239     ┆ 2024-09-0 ┆ … ┆ 3001      ┆ 2024-09-0 ┆ 75944     ┆ 1.0      │\n",
      "│           ┆ 2         ┆           ┆ 2         ┆   ┆           ┆ 2         ┆           ┆          │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n",
      "\n",
      "Product Data shape: (17546, 13)\n",
      "shape: (5, 13)\n",
      "┌────────────┬───────────┬──────────┬──────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
      "│ salesUnitG ┆ salesUnit ┆ baseUnit ┆ category ┆ … ┆ synkkaDat ┆ units     ┆ deposits  ┆ substitut │\n",
      "│ tin        ┆ ---       ┆ ---      ┆ ---      ┆   ┆ a         ┆ ---       ┆ ---       ┆ ions      │\n",
      "│ ---        ┆ str       ┆ str      ┆ str      ┆   ┆ ---       ┆ list[stru ┆ list[stru ┆ ---       │\n",
      "│ str        ┆           ┆          ┆          ┆   ┆ struct[26 ┆ ct[3]]    ┆ ct[3]]    ┆ list[stru │\n",
      "│            ┆           ┆          ┆          ┆   ┆ ]         ┆           ┆           ┆ ct[4]]    │\n",
      "╞════════════╪═══════════╪══════════╪══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ 6409460002 ┆ RAS       ┆ RAS      ┆ 17301    ┆ … ┆ {\"6409460 ┆ [{\"PAL\",\" ┆ []        ┆ null      │\n",
      "│ 724        ┆           ┆          ┆          ┆   ┆ 002724\",\" ┆ 640946004 ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 2025-05-2 ┆ 6902\",50. ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 0T11:02:3 ┆ 0}, {\"KI\" ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 6+0300\",\" ┆ ,\"6409460 ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 2025-09-1 ┆ 046896\",5 ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 5T09:55:5 ┆ .0}, {\"RA ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 5+0300\",[ ┆ S\",\"64094 ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ \"246\"],[{ ┆ 60002724\" ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ \"Forssan  ┆ ,1.0}]    ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ Potato    ┆           ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ Sal…      ┆           ┆           ┆           │\n",
      "│ 6416597016 ┆ SK        ┆ SK       ┆ 21380    ┆ … ┆ {\"6416597 ┆ [{\"SK\",\"6 ┆ []        ┆ null      │\n",
      "│ 579        ┆           ┆          ┆          ┆   ┆ 016579\",\" ┆ 416597016 ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 2025-09-2 ┆ 579\",1.0} ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 5T11:50:4 ┆ , {\"PAL\", ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 7+0300\",\" ┆ null,49.0 ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 2025-05-2 ┆ }]        ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 8T16:57:0 ┆           ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 7+0300\",[ ┆           ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ \"246\"],[{ ┆           ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ \"Torino   ┆           ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 10kg      ┆           ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ macaro…   ┆           ┆           ┆           │\n",
      "│ 6416796729 ┆ ST        ┆ ST       ┆ 21904    ┆ … ┆ {\"6416796 ┆ [{\"KI\",\"6 ┆ []        ┆ null      │\n",
      "│ 140        ┆           ┆          ┆          ┆   ┆ 729140\",\" ┆ 416796809 ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 2025-09-1 ┆ 798\",6.0} ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 9T12:07:3 ┆ , {\"ST\",\" ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 8+0300\",\" ┆ 641679672 ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 2025-09-0 ┆ 9140\",1.0 ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 8T09:53:2 ┆ }]        ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 3+0300\",[ ┆           ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ \"246\"],[{ ┆           ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ \"Puljonki ┆           ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ ® Plum    ┆           ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ Tom…      ┆           ┆           ┆           │\n",
      "│ 5017764112 ┆ KI        ┆ BAG      ┆ 21990    ┆ … ┆ {\"5017764 ┆ [{\"BAG\",\" ┆ []        ┆ null      │\n",
      "│ 264        ┆           ┆          ┆          ┆   ┆ 112257\",\" ┆ 501776411 ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 2025-05-2 ┆ 2257\",1.0 ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 8T17:24:5 ┆ }, {\"KI\", ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 9+0300\",\" ┆ \"50177641 ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 2025-05-2 ┆ 12264\",18 ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 8T17:24:5 ┆ .0}]      ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 9+0300\",[ ┆           ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ \"528\"],[{ ┆           ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ \"40g      ┆           ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ Kettle    ┆           ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ Chips S…  ┆           ┆           ┆           │\n",
      "│ 8714521950 ┆ ST        ┆ ST       ┆ 17401    ┆ … ┆ {null,nul ┆ [{\"KI\",nu ┆ []        ┆ null      │\n",
      "│ 172        ┆           ┆          ┆          ┆   ┆ l,null,nu ┆ ll,8.0},  ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ ll,[{\"TOM ┆ {\"ST\",\"87 ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ BERRY 125 ┆ 145219501 ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ G\",\"en\"}, ┆ 72\",1.0}] ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ {\"TOMAATT ┆           ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ I \"TOM    ┆           ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ BERRY\"    ┆           ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 125G      ┆           ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ RASIA HOL ┆           ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ LANT\",\"fi ┆           ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ \"}, {\"TO… ┆           ┆           ┆           │\n",
      "└────────────┴───────────┴──────────┴──────────┴───┴───────────┴───────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "df_sales = pl.read_csv(SALES_FILE)\n",
    "print(f\"Sales & Deliveries shape: {df_sales.shape}\")\n",
    "print(df_sales.head())\n",
    "\n",
    "# Load purchases (for reference)\n",
    "df_purchases = pl.read_csv(PURCHASES_FILE)\n",
    "print(f\"\\nPurchases shape: {df_purchases.shape}\")\n",
    "print(df_purchases.head())\n",
    "\n",
    "# Load replacement orders\n",
    "df_replacements = pl.read_csv(REPLACEMENT_FILE)\n",
    "print(f\"\\nReplacements shape: {df_replacements.shape}\")\n",
    "print(df_replacements.head())\n",
    "\n",
    "\n",
    "\n",
    "df_products = pl.read_json(PRODUCT_FILE, infer_schema_length=None)\n",
    "\n",
    "print(f\"\\nProduct Data shape: {df_products.shape}\")\n",
    "print(df_products.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba0127b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['order_number',\n",
       "  'order_created_date',\n",
       "  'order_created_time',\n",
       "  'requested_delivery_date',\n",
       "  'customer_number',\n",
       "  'order_row_number',\n",
       "  'product_code',\n",
       "  'order_qty',\n",
       "  'sales_unit',\n",
       "  'delivery_number',\n",
       "  'plant',\n",
       "  'storage_location',\n",
       "  'delivered_qty',\n",
       "  'transfer_number',\n",
       "  'warehouse_number',\n",
       "  'picking_confirmed_date',\n",
       "  'picking_confirmed_time',\n",
       "  'picking_picked_qty'],\n",
       " ['order_number',\n",
       "  'po_row_number',\n",
       "  'customer_number',\n",
       "  'po_created_date',\n",
       "  'requested_delivery_date',\n",
       "  'product_code',\n",
       "  'plant',\n",
       "  'storage_location',\n",
       "  'ordered_qty',\n",
       "  'unit',\n",
       "  'received_qty'],\n",
       " ['order_number',\n",
       "  'order_created_date',\n",
       "  'order_created_time',\n",
       "  'requested_delivery_date',\n",
       "  'customer_number',\n",
       "  'order_row_number',\n",
       "  'product_code',\n",
       "  'order_qty',\n",
       "  'sales_unit',\n",
       "  'delivery_number',\n",
       "  'plant',\n",
       "  'storage_location',\n",
       "  'delivered_qty',\n",
       "  'transfer_number',\n",
       "  'warehouse_number',\n",
       "  'picking_confirmed_date',\n",
       "  'picking_confirmed_time',\n",
       "  'picking_picked_qty'],\n",
       " ['salesUnitGtin',\n",
       "  'salesUnit',\n",
       "  'baseUnit',\n",
       "  'category',\n",
       "  'allowedLotSize',\n",
       "  'deleted',\n",
       "  'temperatureCondition',\n",
       "  'vendorName',\n",
       "  'countryOfOrigin',\n",
       "  'synkkaData',\n",
       "  'units',\n",
       "  'deposits',\n",
       "  'substitutions'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales.columns , df_purchases.columns, df_replacements.columns, df_products.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "404b69bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DATA EXPLORATION\n",
      "================================================================================\n",
      "\n",
      "--- SALES & DELIVERIES ---\n",
      "Columns: ['order_number', 'order_created_date', 'order_created_time', 'requested_delivery_date', 'customer_number', 'order_row_number', 'product_code', 'order_qty', 'sales_unit', 'delivery_number', 'plant', 'storage_location', 'delivered_qty', 'transfer_number', 'warehouse_number', 'picking_confirmed_date', 'picking_confirmed_time', 'picking_picked_qty']\n",
      "\n",
      "Data types:\n",
      "[Int64, String, Int64, String, Int64, Int64, Int64, Float64, String, Int64, Int64, Int64, Float64, Int64, Int64, String, Int64, Float64]\n",
      "\n",
      "Null counts:\n",
      "shape: (1, 18)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ order_num ┆ order_cre ┆ order_cre ┆ requested ┆ … ┆ warehouse ┆ picking_c ┆ picking_c ┆ picking_ │\n",
      "│ ber       ┆ ated_date ┆ ated_time ┆ _delivery ┆   ┆ _number   ┆ onfirmed_ ┆ onfirmed_ ┆ picked_q │\n",
      "│ ---       ┆ ---       ┆ ---       ┆ _date     ┆   ┆ ---       ┆ date      ┆ time      ┆ ty       │\n",
      "│ u32       ┆ u32       ┆ u32       ┆ ---       ┆   ┆ u32       ┆ ---       ┆ ---       ┆ ---      │\n",
      "│           ┆           ┆           ┆ u32       ┆   ┆           ┆ u32       ┆ u32       ┆ u32      │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 0         ┆ 0         ┆ 0         ┆ 0         ┆ … ┆ 173392    ┆ 173392    ┆ 173392    ┆ 173392   │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n",
      "\n",
      "Unique values:\n",
      "  - Orders: 696991\n",
      "  - Customers: 5282\n",
      "  - Products: 15236\n",
      "\n",
      "  - Shortage rate: 2.29%\n",
      "  - Null delivery rate: 2.00%\n",
      "\n",
      "--- PURCHASES ---\n",
      "Columns: ['order_number', 'po_row_number', 'customer_number', 'po_created_date', 'requested_delivery_date', 'product_code', 'plant', 'storage_location', 'ordered_qty', 'unit', 'received_qty']\n",
      "Unique orders: 303206\n",
      "Unique products: 14110\n",
      "  - Purchase shortage rate: 3.79%\n",
      "  - Order overlap: 0/303206 purchases appear in sales\n",
      "\n",
      "--- PRODUCT DATA ---\n",
      "Columns: ['salesUnitGtin', 'salesUnit', 'baseUnit', 'category', 'allowedLotSize', 'deleted', 'temperatureCondition', 'vendorName', 'countryOfOrigin', 'synkkaData', 'units', 'deposits', 'substitutions']\n",
      "Unique products (salesUnitGtin): 17388\n",
      "  - Product code overlap: 0/15236 sales products found in product data\n",
      "\n",
      "Vendor distribution:\n",
      "shape: (10, 2)\n",
      "┌─────────────────────────────────────┬───────┐\n",
      "│ vendorName                          ┆ count │\n",
      "│ ---                                 ┆ ---   │\n",
      "│ str                                 ┆ u32   │\n",
      "╞═════════════════════════════════════╪═══════╡\n",
      "│ JFC NORDEN (SWEDEN) AB TEOLLINEN    ┆ 21    │\n",
      "│ BLUE WORLD SEAFOOD B.V.             ┆ 2     │\n",
      "│ TARHURIN PAPU OY / PAKASTE          ┆ 3     │\n",
      "│ MCCAIN FOODS EUROPE BV              ┆ 24    │\n",
      "│ IMPERIAL BRANDS FINLAND OY          ┆ 7     │\n",
      "│ AT SAUCE OY                         ┆ 22    │\n",
      "│ SUOMEN LÄMPÖMITTARI OY - FINSKA TER ┆ 8     │\n",
      "│ THE GREAT FOOD COMPANY OY           ┆ 4     │\n",
      "│ ÄRMÄTTI OY                          ┆ 1     │\n",
      "│ JK-DECOREST OY                      ┆ 1     │\n",
      "└─────────────────────────────────────┴───────┘\n",
      "\n",
      "Category distribution:\n",
      "shape: (10, 2)\n",
      "┌──────────┬───────┐\n",
      "│ category ┆ count │\n",
      "│ ---      ┆ ---   │\n",
      "│ str      ┆ u32   │\n",
      "╞══════════╪═══════╡\n",
      "│ 18701    ┆ 81    │\n",
      "│ 20023    ┆ 30    │\n",
      "│ 63131    ┆ 10    │\n",
      "│ 17481    ┆ 17    │\n",
      "│ 17203    ┆ 82    │\n",
      "│ 63272    ┆ 46    │\n",
      "│ 10402    ┆ 66    │\n",
      "│ 67730    ┆ 6     │\n",
      "│ 64000    ┆ 35    │\n",
      "│ 10515    ┆ 42    │\n",
      "└──────────┴───────┘\n",
      "\n",
      "--- REPLACEMENT ORDERS ---\n",
      "Shape: (15069, 18)\n",
      "Columns: ['order_number', 'order_created_date', 'order_created_time', 'requested_delivery_date', 'customer_number', 'order_row_number', 'product_code', 'order_qty', 'sales_unit', 'delivery_number', 'plant', 'storage_location', 'delivered_qty', 'transfer_number', 'warehouse_number', 'picking_confirmed_date', 'picking_confirmed_time', 'picking_picked_qty']\n",
      "\n",
      "Note: Replacement file has same structure as sales. Need to identify replacements differently.\n",
      "  - Unique orders: 11520\n",
      "  - Unique products: 3535\n"
     ]
    }
   ],
   "source": [
    "def explore_dataframes():\n",
    "    \"\"\"Explore the structure and relationships of datasets\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DATA EXPLORATION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Sales & Deliveries Analysis\n",
    "    print(\"\\n--- SALES & DELIVERIES ---\")\n",
    "    print(f\"Columns: {df_sales.columns}\")\n",
    "    print(f\"\\nData types:\\n{df_sales.dtypes}\")\n",
    "    print(f\"\\nNull counts:\\n{df_sales.null_count()}\")\n",
    "    print(f\"\\nUnique values:\")\n",
    "    print(f\"  - Orders: {df_sales['order_number'].n_unique()}\")\n",
    "    print(f\"  - Customers: {df_sales['customer_number'].n_unique()}\")\n",
    "    print(f\"  - Products: {df_sales['product_code'].n_unique()}\")\n",
    "    \n",
    "    # Check for shortages in sales\n",
    "    shortage_check = df_sales.with_columns([\n",
    "        (pl.col('order_qty') > pl.col('delivered_qty')).alias('is_shortage'),\n",
    "        pl.col('delivered_qty').is_null().alias('is_null_delivery')\n",
    "    ])\n",
    "    \n",
    "    shortage_rate = shortage_check['is_shortage'].mean() * 100\n",
    "    null_delivery_rate = shortage_check['is_null_delivery'].mean() * 100\n",
    "    \n",
    "    print(f\"\\n  - Shortage rate: {shortage_rate:.2f}%\")\n",
    "    print(f\"  - Null delivery rate: {null_delivery_rate:.2f}%\")\n",
    "    \n",
    "    # Purchases Analysis\n",
    "    print(\"\\n--- PURCHASES ---\")\n",
    "    print(f\"Columns: {df_purchases.columns}\")\n",
    "    print(f\"Unique orders: {df_purchases['order_number'].n_unique()}\")\n",
    "    print(f\"Unique products: {df_purchases['product_code'].n_unique()}\")\n",
    "    \n",
    "    # Check for shortages in purchases\n",
    "    purchase_shortage_check = df_purchases.with_columns([\n",
    "        (pl.col('ordered_qty') > pl.col('received_qty')).alias('is_shortage')\n",
    "    ])\n",
    "    purchase_shortage_rate = purchase_shortage_check['is_shortage'].mean() * 100\n",
    "    print(f\"  - Purchase shortage rate: {purchase_shortage_rate:.2f}%\")\n",
    "    \n",
    "    # Check overlap between purchases and sales\n",
    "    purchase_orders = set(df_purchases['order_number'].unique().to_list())\n",
    "    sales_orders = set(df_sales['order_number'].unique().to_list())\n",
    "    overlap = len(purchase_orders.intersection(sales_orders))\n",
    "    print(f\"  - Order overlap: {overlap}/{len(purchase_orders)} purchases appear in sales\")\n",
    "    \n",
    "    # Product Data Analysis\n",
    "    print(\"\\n--- PRODUCT DATA ---\")\n",
    "    print(f\"Columns: {df_products.columns}\")\n",
    "    \n",
    "    # Check if product_code matches salesUnitGtin or needs mapping\n",
    "    if 'salesUnitGtin' in df_products.columns:\n",
    "        print(f\"Unique products (salesUnitGtin): {df_products['salesUnitGtin'].n_unique()}\")\n",
    "        \n",
    "        # Check overlap with sales product_code\n",
    "        sales_products = set(df_sales['product_code'].unique().to_list())\n",
    "        product_gtins = set(df_products['salesUnitGtin'].unique().to_list())\n",
    "        product_overlap = len(sales_products.intersection(product_gtins))\n",
    "        print(f\"  - Product code overlap: {product_overlap}/{len(sales_products)} sales products found in product data\")\n",
    "    \n",
    "    if 'vendorName' in df_products.columns:\n",
    "        print(f\"\\nVendor distribution:\")\n",
    "        print(df_products['vendorName'].value_counts().head(10))\n",
    "    \n",
    "    if 'category' in df_products.columns:\n",
    "        print(f\"\\nCategory distribution:\")\n",
    "        print(df_products['category'].value_counts().head(10))\n",
    "    \n",
    "    # Replacement Orders Analysis\n",
    "    print(\"\\n--- REPLACEMENT ORDERS ---\")\n",
    "    print(f\"Shape: {df_replacements.shape}\")\n",
    "    print(f\"Columns: {df_replacements.columns}\")\n",
    "    print(\"\\nNote: Replacement file has same structure as sales. Need to identify replacements differently.\")\n",
    "    print(f\"  - Unique orders: {df_replacements['order_number'].n_unique()}\")\n",
    "    print(f\"  - Unique products: {df_replacements['product_code'].n_unique()}\")\n",
    "    \n",
    "    return shortage_check\n",
    "\n",
    "shortage_check = explore_dataframes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41361e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DATA CLEANING\n",
      "================================================================================\n",
      "\n",
      "1. Converting date columns...\n",
      "  ✓ Converted order_created_date\n",
      "  ✓ Converted requested_delivery_date\n",
      "  ✓ Converted picking_confirmed_date\n",
      "\n",
      "2. Handling placeholder dates...\n",
      "  - picking_confirmed_date: 360459 placeholder dates -> set to null\n",
      "\n",
      "3. Handling null delivered quantities...\n",
      "  - Null delivered_qty: 147370\n",
      "  - Null picking_picked_qty: 173392\n",
      "\n",
      "4. Creating target variable...\n",
      "  - Shortage instances: 292511/7357509 (3.98%)\n",
      "\n",
      "5. Merging with product data...\n",
      "  - Sales product_code dtype: Int64\n",
      "  - Product salesUnitGtin dtype: String\n",
      "  - After casting - Sales product_code dtype: String\n",
      "  - After casting - Product product_code dtype: String\n",
      "  - Rows after merge: 7357509 (original: 7357509)\n",
      "  - Rows with product data: 0/7357509 (0.00%)\n",
      "\n",
      "6. Handling categorical nulls...\n",
      "  - storage_location: 147384 nulls -> filled with 'UNKNOWN'\n",
      "  - plant: 147370 nulls -> filled with 'UNKNOWN'\n",
      "  - vendorName: 7357509 nulls -> filled with 'UNKNOWN'\n",
      "  - category: 7357509 nulls -> filled with 'UNKNOWN'\n",
      "  - temperatureCondition: 7357509 nulls -> filled with 'UNKNOWN'\n",
      "\n",
      "7. Removing duplicates...\n",
      "  - Removed 7283 duplicates\n",
      "\n",
      "✓ Cleaning complete!\n",
      "Final shape: (7350226, 31)\n",
      "\n",
      "Cleaned data sample:\n",
      "shape: (10, 7)\n",
      "┌──────────────┬──────────────┬───────────┬───────────────┬─────────────┬────────────┬──────────┐\n",
      "│ order_number ┆ product_code ┆ order_qty ┆ delivered_qty ┆ is_shortage ┆ vendorName ┆ category │\n",
      "│ ---          ┆ ---          ┆ ---       ┆ ---           ┆ ---         ┆ ---        ┆ ---      │\n",
      "│ i64          ┆ str          ┆ f64       ┆ f64           ┆ i8          ┆ str        ┆ str      │\n",
      "╞══════════════╪══════════════╪═══════════╪═══════════════╪═════════════╪════════════╪══════════╡\n",
      "│ 10233710     ┆ 410605       ┆ 1.0       ┆ 1.0           ┆ 0           ┆ UNKNOWN    ┆ UNKNOWN  │\n",
      "│ 10392047     ┆ 402962       ┆ 1.0       ┆ 1.0           ┆ 0           ┆ UNKNOWN    ┆ UNKNOWN  │\n",
      "│ 10470533     ┆ 403044       ┆ 7.0       ┆ 0.0           ┆ 1           ┆ UNKNOWN    ┆ UNKNOWN  │\n",
      "│ 10503390     ┆ 400431       ┆ 2.0       ┆ 2.0           ┆ 0           ┆ UNKNOWN    ┆ UNKNOWN  │\n",
      "│ 10218531     ┆ 401016       ┆ 8.0       ┆ 8.25          ┆ 0           ┆ UNKNOWN    ┆ UNKNOWN  │\n",
      "│ 10605112     ┆ 400227       ┆ 1.0       ┆ 1.0           ┆ 0           ┆ UNKNOWN    ┆ UNKNOWN  │\n",
      "│ 10361292     ┆ 404179       ┆ 4.0       ┆ 4.0           ┆ 0           ┆ UNKNOWN    ┆ UNKNOWN  │\n",
      "│ 10430103     ┆ 416561       ┆ 6.0       ┆ 6.21          ┆ 0           ┆ UNKNOWN    ┆ UNKNOWN  │\n",
      "│ 10176308     ┆ 400006       ┆ 2.0       ┆ 2.0           ┆ 0           ┆ UNKNOWN    ┆ UNKNOWN  │\n",
      "│ 10096418     ┆ 417078       ┆ 2.0       ┆ 2.0           ┆ 0           ┆ UNKNOWN    ┆ UNKNOWN  │\n",
      "└──────────────┴──────────────┴───────────┴───────────────┴─────────────┴────────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "def clean_data(df_sales, df_products):\n",
    "    \"\"\"Clean and preprocess the data\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DATA CLEANING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    df = df_sales.clone()\n",
    "    \n",
    "    # 1. Convert date columns to datetime\n",
    "    print(\"\\n1. Converting date columns...\")\n",
    "    date_columns = ['order_created_date', 'requested_delivery_date', 'picking_confirmed_date']\n",
    "    \n",
    "    for col in date_columns:\n",
    "        if col in df.columns:\n",
    "            try:\n",
    "                df = df.with_columns([\n",
    "                    pl.col(col).str.strptime(pl.Date, format=\"%Y-%m-%d\", strict=False).alias(col)\n",
    "                ])\n",
    "                print(f\"  ✓ Converted {col}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  ✗ Error converting {col}: {e}\")\n",
    "    \n",
    "    # 2. Handle '1970-01-01' dates (placeholder dates)\n",
    "    print(\"\\n2. Handling placeholder dates...\")\n",
    "    for col in date_columns:\n",
    "        if col in df.columns and df[col].dtype == pl.Date:\n",
    "            count_1970 = df.filter(pl.col(col) == datetime(1970, 1, 1).date()).height\n",
    "            if count_1970 > 0:\n",
    "                print(f\"  - {col}: {count_1970} placeholder dates -> set to null\")\n",
    "                df = df.with_columns([\n",
    "                    pl.when(pl.col(col) == datetime(1970, 1, 1).date())\n",
    "                    .then(None)\n",
    "                    .otherwise(pl.col(col))\n",
    "                    .alias(col)\n",
    "                ])\n",
    "    \n",
    "    # 3. Handle null delivered_qty (assume 0 if order exists but no delivery)\n",
    "    print(\"\\n3. Handling null delivered quantities...\")\n",
    "    null_delivered = df['delivered_qty'].is_null().sum()\n",
    "    print(f\"  - Null delivered_qty: {null_delivered}\")\n",
    "    \n",
    "    df = df.with_columns([\n",
    "        pl.col('delivered_qty').fill_null(0)\n",
    "    ])\n",
    "    \n",
    "    # 4. Handle null picking_picked_qty\n",
    "    null_picked = df['picking_picked_qty'].is_null().sum()\n",
    "    print(f\"  - Null picking_picked_qty: {null_picked}\")\n",
    "    df = df.with_columns([\n",
    "        pl.col('picking_picked_qty').fill_null(0)\n",
    "    ])\n",
    "    \n",
    "    # 5. Create target variable: is_shortage\n",
    "    print(\"\\n4. Creating target variable...\")\n",
    "    df = df.with_columns([\n",
    "        (\n",
    "            (pl.col('order_qty') > pl.col('delivered_qty')) |\n",
    "            ((pl.col('delivered_qty') == 0) & (pl.col('order_qty') > 0))\n",
    "        ).cast(pl.Int8).alias('is_shortage')\n",
    "    ])\n",
    "    \n",
    "    shortage_count = df['is_shortage'].sum()\n",
    "    total_count = df.height\n",
    "    print(f\"  - Shortage instances: {shortage_count}/{total_count} ({shortage_count/total_count*100:.2f}%)\")\n",
    "    \n",
    "    # 6. Merge with product data (using salesUnitGtin as product_code)\n",
    "    print(\"\\n5. Merging with product data...\")\n",
    "    print(f\"  - Sales product_code dtype: {df['product_code'].dtype}\")\n",
    "    print(f\"  - Product salesUnitGtin dtype: {df_products['salesUnitGtin'].dtype}\")\n",
    "    \n",
    "    original_rows = df.height\n",
    "    \n",
    "    # Convert product_code in sales to string to match salesUnitGtin\n",
    "    df = df.with_columns([\n",
    "        pl.col('product_code').cast(pl.Utf8).alias('product_code')\n",
    "    ])\n",
    "    \n",
    "    # Rename salesUnitGtin to product_code for joining\n",
    "    df_products_renamed = df_products.rename({'salesUnitGtin': 'product_code'})\n",
    "    \n",
    "    # Ensure product_code in products is also string\n",
    "    df_products_renamed = df_products_renamed.with_columns([\n",
    "        pl.col('product_code').cast(pl.Utf8)\n",
    "    ])\n",
    "    \n",
    "    print(f\"  - After casting - Sales product_code dtype: {df['product_code'].dtype}\")\n",
    "    print(f\"  - After casting - Product product_code dtype: {df_products_renamed['product_code'].dtype}\")\n",
    "    \n",
    "    df = df.join(df_products_renamed, on='product_code', how='left')\n",
    "    print(f\"  - Rows after merge: {df.height} (original: {original_rows})\")\n",
    "    \n",
    "    # Check how many products matched\n",
    "    matched_products = df.filter(pl.col('vendorName').is_not_null()).height\n",
    "    print(f\"  - Rows with product data: {matched_products}/{df.height} ({matched_products/df.height*100:.2f}%)\")\n",
    "    \n",
    "    # 7. Handle categorical nulls\n",
    "    print(\"\\n6. Handling categorical nulls...\")\n",
    "    categorical_cols = ['storage_location', 'plant', 'vendorName', 'category', 'temperatureCondition']\n",
    "    for col in categorical_cols:\n",
    "        if col in df.columns:\n",
    "            null_count = df[col].is_null().sum()\n",
    "            if null_count > 0:\n",
    "                print(f\"  - {col}: {null_count} nulls -> filled with 'UNKNOWN'\")\n",
    "                df = df.with_columns([\n",
    "                    pl.col(col).fill_null('UNKNOWN')\n",
    "                ])\n",
    "    \n",
    "    # 8. Remove duplicates\n",
    "    print(\"\\n7. Removing duplicates...\")\n",
    "    original_rows = df.height\n",
    "    df = df.unique()\n",
    "    removed = original_rows - df.height\n",
    "    if removed > 0:\n",
    "        print(f\"  - Removed {removed} duplicates\")\n",
    "    else:\n",
    "        print(f\"  - No duplicates found\")\n",
    "    \n",
    "    print(\"\\n✓ Cleaning complete!\")\n",
    "    print(f\"Final shape: {df.shape}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Clean the data\n",
    "df_clean = clean_data(df_sales, df_products)\n",
    "print(\"\\nCleaned data sample:\")\n",
    "print(df_clean.select(['order_number', 'product_code', 'order_qty', 'delivered_qty', 'is_shortage', 'vendorName', 'category']).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a0aa051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FEATURE ENGINEERING\n",
      "================================================================================\n",
      "\n",
      "--- Creating Date Features ---\n",
      "  ✓ Created day_of_week, day_of_month, month, quarter, year, is_weekend\n",
      "  ✓ Created lead_time_days\n",
      "  ✗ Could not extract order_hour: invalid series dtype: expected `String`, got `i64` for series with name `order_created_time`\n",
      "\n",
      "--- Creating Product Features ---\n",
      "  ✓ Created product_shortage_rate, product_avg_order_qty, product_order_qty_std\n",
      "  ✓ Created category_shortage_rate\n",
      "  ✓ Created temp_condition_shortage_rate\n",
      "\n",
      "--- Creating Customer Features ---\n",
      "  ✓ Created customer_shortage_rate, customer_total_order_qty, customer_order_count\n",
      "  ✓ Created customer_product_shortage_rate\n",
      "\n",
      "--- Creating Vendor Features ---\n",
      "  ✓ Created vendor_shortage_rate (vendor reliability)\n",
      "\n",
      "--- Creating Location Features ---\n",
      "  ✓ Created plant_shortage_rate\n",
      "  ✓ Created storage_shortage_rate\n",
      "\n",
      "--- Creating Replacement Features ---\n",
      "  ✓ Created replacement_frequency\n",
      "\n",
      "✓ Feature engineering complete!\n",
      "Total columns: 57\n",
      "Shape: (7350226, 57)\n",
      "\n",
      "Sample of engineered features:\n",
      "shape: (10, 7)\n",
      "┌──────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┐\n",
      "│ order_number ┆ product_cod ┆ is_shortage ┆ product_sho ┆ customer_sh ┆ vendor_shor ┆ lead_time_d │\n",
      "│ ---          ┆ e           ┆ ---         ┆ rtage_rate  ┆ ortage_rate ┆ tage_rate   ┆ ays         │\n",
      "│ i64          ┆ ---         ┆ i8          ┆ ---         ┆ ---         ┆ ---         ┆ ---         │\n",
      "│              ┆ str         ┆             ┆ f64         ┆ f64         ┆ f64         ┆ i64         │\n",
      "╞══════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╡\n",
      "│ 10000557     ┆ 408336      ┆ 0           ┆ 0.020673    ┆ 0.020436    ┆ 0.03977     ┆ 2           │\n",
      "│ 10000489     ┆ 410397      ┆ 0           ┆ 0.02071     ┆ 0.050607    ┆ 0.03977     ┆ 1           │\n",
      "│ 10000646     ┆ 402751      ┆ 0           ┆ 0.009132    ┆ 0.028641    ┆ 0.03977     ┆ 3           │\n",
      "│ 10000299     ┆ 411134      ┆ 0           ┆ 0.011655    ┆ 0.045214    ┆ 0.03977     ┆ 3           │\n",
      "│ 10000400     ┆ 404171      ┆ 0           ┆ 0.011657    ┆ 0.014246    ┆ 0.03977     ┆ 1           │\n",
      "│ 10000232     ┆ 400846      ┆ 0           ┆ 0.003896    ┆ 0.029963    ┆ 0.03977     ┆ 1           │\n",
      "│ 10000674     ┆ 400462      ┆ 0           ┆ 0.007931    ┆ 0.031981    ┆ 0.03977     ┆ 2           │\n",
      "│ 10000112     ┆ 408855      ┆ 0           ┆ 0.015244    ┆ 0.030446    ┆ 0.03977     ┆ 3           │\n",
      "│ 10000274     ┆ 402546      ┆ 0           ┆ 0.019994    ┆ 0.018339    ┆ 0.03977     ┆ 1           │\n",
      "│ 10000592     ┆ 401493      ┆ 0           ┆ 0.023543    ┆ 0.032941    ┆ 0.03977     ┆ 1           │\n",
      "└──────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mfrfo\\AppData\\Local\\Temp\\ipykernel_77616\\91580802.py:152: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias('replacement_frequency')\n"
     ]
    }
   ],
   "source": [
    "def create_date_features(df):\n",
    "    \"\"\"Create time-based features\"\"\"\n",
    "    \n",
    "    print(\"\\n--- Creating Date Features ---\")\n",
    "    \n",
    "    # From order_created_date\n",
    "    df = df.with_columns([\n",
    "        pl.col('order_created_date').dt.weekday().alias('order_day_of_week'),\n",
    "        pl.col('order_created_date').dt.day().alias('order_day_of_month'),\n",
    "        pl.col('order_created_date').dt.month().alias('order_month'),\n",
    "        pl.col('order_created_date').dt.quarter().alias('order_quarter'),\n",
    "        pl.col('order_created_date').dt.year().alias('order_year'),\n",
    "        (pl.col('order_created_date').dt.weekday() >= 5).cast(pl.Int8).alias('is_weekend')\n",
    "    ])\n",
    "    print(\"  ✓ Created day_of_week, day_of_month, month, quarter, year, is_weekend\")\n",
    "    \n",
    "    # Calculate lead time\n",
    "    df = df.with_columns([\n",
    "        (pl.col('requested_delivery_date') - pl.col('order_created_date'))\n",
    "        .dt.total_days()\n",
    "        .alias('lead_time_days')\n",
    "    ])\n",
    "    print(\"  ✓ Created lead_time_days\")\n",
    "    \n",
    "    # Time of day from order_created_time\n",
    "    try:\n",
    "        df = df.with_columns([\n",
    "            pl.col('order_created_time').str.slice(0, 2).cast(pl.Int32, strict=False).alias('order_hour')\n",
    "        ])\n",
    "        print(\"  ✓ Created order_hour\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Could not extract order_hour: {e}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_product_features(df):\n",
    "    \"\"\"Create product-level aggregated features\"\"\"\n",
    "    \n",
    "    print(\"\\n--- Creating Product Features ---\")\n",
    "    \n",
    "    # Sort by date for proper temporal aggregation\n",
    "    df = df.sort('order_created_date')\n",
    "    \n",
    "    # 1. Historical shortage rate per product\n",
    "    product_stats = df.group_by('product_code').agg([\n",
    "        pl.col('is_shortage').mean().alias('product_shortage_rate'),\n",
    "        pl.col('order_qty').mean().alias('product_avg_order_qty'),\n",
    "        pl.col('order_qty').std().alias('product_order_qty_std'),\n",
    "        pl.col('delivered_qty').mean().alias('product_avg_delivered_qty'),\n",
    "        pl.col('order_number').n_unique().alias('product_order_count')\n",
    "    ])\n",
    "    \n",
    "    df = df.join(product_stats, on='product_code', how='left', suffix='_stat')\n",
    "    print(\"  ✓ Created product_shortage_rate, product_avg_order_qty, product_order_qty_std\")\n",
    "    \n",
    "    # 2. Category-based features\n",
    "    if 'category' in df.columns:\n",
    "        category_stats = df.group_by('category').agg([\n",
    "            pl.col('is_shortage').mean().alias('category_shortage_rate')\n",
    "        ])\n",
    "        df = df.join(category_stats, on='category', how='left', suffix='_cat')\n",
    "        print(\"  ✓ Created category_shortage_rate\")\n",
    "    \n",
    "    # 3. Temperature condition features (perishables might have higher shortage)\n",
    "    if 'temperatureCondition' in df.columns:\n",
    "        temp_stats = df.group_by('temperatureCondition').agg([\n",
    "            pl.col('is_shortage').mean().alias('temp_condition_shortage_rate')\n",
    "        ])\n",
    "        df = df.join(temp_stats, on='temperatureCondition', how='left', suffix='_temp')\n",
    "        print(\"  ✓ Created temp_condition_shortage_rate\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_customer_features(df):\n",
    "    \"\"\"Create customer-level aggregated features\"\"\"\n",
    "    \n",
    "    print(\"\\n--- Creating Customer Features ---\")\n",
    "    \n",
    "    # Customer statistics\n",
    "    customer_stats = df.group_by('customer_number').agg([\n",
    "        pl.col('is_shortage').mean().alias('customer_shortage_rate'),\n",
    "        pl.col('order_qty').sum().alias('customer_total_order_qty'),\n",
    "        pl.col('order_number').n_unique().alias('customer_order_count'),\n",
    "        pl.col('lead_time_days').mean().alias('customer_avg_lead_time')\n",
    "    ])\n",
    "    \n",
    "    df = df.join(customer_stats, on='customer_number', how='left', suffix='_cust')\n",
    "    print(\"  ✓ Created customer_shortage_rate, customer_total_order_qty, customer_order_count\")\n",
    "    \n",
    "    # Customer-Product combination\n",
    "    customer_product_stats = df.group_by(['customer_number', 'product_code']).agg([\n",
    "        pl.col('is_shortage').mean().alias('customer_product_shortage_rate'),\n",
    "        pl.col('order_number').n_unique().alias('customer_product_order_count')\n",
    "    ])\n",
    "    \n",
    "    df = df.join(customer_product_stats, on=['customer_number', 'product_code'], how='left', suffix='_cp')\n",
    "    print(\"  ✓ Created customer_product_shortage_rate\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_vendor_features(df):\n",
    "    \"\"\"Create vendor/supplier reliability features\"\"\"\n",
    "    \n",
    "    print(\"\\n--- Creating Vendor Features ---\")\n",
    "    \n",
    "    if 'vendorName' in df.columns:\n",
    "        vendor_stats = df.group_by('vendorName').agg([\n",
    "            pl.col('is_shortage').mean().alias('vendor_shortage_rate'),\n",
    "            pl.col('order_number').n_unique().alias('vendor_order_count')\n",
    "        ])\n",
    "        \n",
    "        df = df.join(vendor_stats, on='vendorName', how='left', suffix='_vend')\n",
    "        print(\"  ✓ Created vendor_shortage_rate (vendor reliability)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_location_features(df):\n",
    "    \"\"\"Create plant and storage location features\"\"\"\n",
    "    \n",
    "    print(\"\\n--- Creating Location Features ---\")\n",
    "    \n",
    "    # Plant statistics\n",
    "    plant_stats = df.group_by('plant').agg([\n",
    "        pl.col('is_shortage').mean().alias('plant_shortage_rate'),\n",
    "        pl.col('order_number').n_unique().alias('plant_order_count')\n",
    "    ])\n",
    "    df = df.join(plant_stats, on='plant', how='left', suffix='_plant')\n",
    "    print(\"  ✓ Created plant_shortage_rate\")\n",
    "    \n",
    "    # Storage location statistics\n",
    "    storage_stats = df.group_by('storage_location').agg([\n",
    "        pl.col('is_shortage').mean().alias('storage_shortage_rate')\n",
    "    ])\n",
    "    df = df.join(storage_stats, on='storage_location', how='left', suffix='_stor')\n",
    "    print(\"  ✓ Created storage_shortage_rate\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_replacement_features(df, df_replacements):\n",
    "    \"\"\"Create features indicating products that often need replacements\"\"\"\n",
    "    \n",
    "    print(\"\\n--- Creating Replacement Features ---\")\n",
    "    \n",
    "    # Since replacements has same structure as sales, we need to identify which orders are replacements\n",
    "    # For now, count how often each product appears in replacement file\n",
    "    replacement_counts = df_replacements.group_by('product_code').agg([\n",
    "        pl.count().alias('replacement_frequency')\n",
    "    ])\n",
    "    \n",
    "    # Cast product_code to string in replacement_counts to match\n",
    "    replacement_counts = replacement_counts.with_columns([\n",
    "        pl.col('product_code').cast(pl.Utf8)\n",
    "    ])\n",
    "    \n",
    "    df = df.join(replacement_counts, on='product_code', how='left')\n",
    "    df = df.with_columns([\n",
    "        pl.col('replacement_frequency').fill_null(0)\n",
    "    ])\n",
    "    \n",
    "    print(\"  ✓ Created replacement_frequency\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Apply all feature engineering\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_features = df_clean.clone()\n",
    "df_features = create_date_features(df_features)\n",
    "df_features = create_product_features(df_features)\n",
    "df_features = create_customer_features(df_features)\n",
    "df_features = create_vendor_features(df_features)\n",
    "df_features = create_location_features(df_features)\n",
    "df_features = create_replacement_features(df_features, df_replacements)\n",
    "\n",
    "print(\"\\n✓ Feature engineering complete!\")\n",
    "print(f\"Total columns: {len(df_features.columns)}\")\n",
    "print(f\"Shape: {df_features.shape}\")\n",
    "\n",
    "# Show a sample of features\n",
    "print(\"\\nSample of engineered features:\")\n",
    "feature_sample_cols = ['order_number', 'product_code', 'is_shortage', 'product_shortage_rate', \n",
    "                       'customer_shortage_rate', 'vendor_shortage_rate', 'lead_time_days']\n",
    "available_cols = [col for col in feature_sample_cols if col in df_features.columns]\n",
    "print(df_features.select(available_cols).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca0e66ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating product code mismatch...\n",
      "\n",
      "Sample product codes from sales:\n",
      "shape: (20, 1)\n",
      "┌──────────────┐\n",
      "│ product_code │\n",
      "│ ---          │\n",
      "│ i64          │\n",
      "╞══════════════╡\n",
      "│ 415793       │\n",
      "│ 406355       │\n",
      "│ 400722       │\n",
      "│ 402437       │\n",
      "│ 405834       │\n",
      "│ 403351       │\n",
      "│ 407939       │\n",
      "│ 410696       │\n",
      "│ 410949       │\n",
      "│ 401764       │\n",
      "│ 406611       │\n",
      "│ 405444       │\n",
      "│ 405316       │\n",
      "│ 400987       │\n",
      "│ 409892       │\n",
      "│ 407814       │\n",
      "│ 406873       │\n",
      "│ 407016       │\n",
      "│ 400996       │\n",
      "│ 413575       │\n",
      "└──────────────┘\n",
      "\n",
      "Sample salesUnitGtin from products:\n",
      "shape: (20, 1)\n",
      "┌───────────────┐\n",
      "│ salesUnitGtin │\n",
      "│ ---           │\n",
      "│ str           │\n",
      "╞═══════════════╡\n",
      "│ 6413467612305 │\n",
      "│ 8591346304553 │\n",
      "│ 7391440885009 │\n",
      "│ 8414933008583 │\n",
      "│ 6408431305109 │\n",
      "│ 6411440060600 │\n",
      "│ 2300760200000 │\n",
      "│ 6413466101503 │\n",
      "│ 6430018362052 │\n",
      "│ 6408430339457 │\n",
      "│ 6418047431512 │\n",
      "│ 7310800017690 │\n",
      "│ 7622200609680 │\n",
      "│ 6409100272616 │\n",
      "│ 6418675197170 │\n",
      "│ 6410381083068 │\n",
      "│ 6430025257457 │\n",
      "│ 5703538134777 │\n",
      "│ 7322302443457 │\n",
      "│ 6414505163346 │\n",
      "└───────────────┘\n",
      "\n",
      "SalesUnitGtin data types and samples:\n",
      "shape: (20, 1)\n",
      "┌───────────────┐\n",
      "│ salesUnitGtin │\n",
      "│ ---           │\n",
      "│ str           │\n",
      "╞═══════════════╡\n",
      "│ 6409460002724 │\n",
      "│ 6416597016579 │\n",
      "│ 6416796729140 │\n",
      "│ 5017764112264 │\n",
      "│ 8714521950172 │\n",
      "│ 5411188082583 │\n",
      "│ 6430104952570 │\n",
      "│ 6416250007890 │\n",
      "│ 8076800035988 │\n",
      "│ 6408190005609 │\n",
      "│ 7321031479751 │\n",
      "│ 7310500037240 │\n",
      "│ 2300121300000 │\n",
      "│ 2300100100000 │\n",
      "│ 2300121600000 │\n",
      "│ 2300106200000 │\n",
      "│ 2300110200000 │\n",
      "│ 6430061750011 │\n",
      "│ 6411404017329 │\n",
      "│ 5017764112370 │\n",
      "└───────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Let's investigate the product code mismatch\n",
    "print(\"Investigating product code mismatch...\")\n",
    "print(\"\\nSample product codes from sales:\")\n",
    "print(df_sales.select('product_code').unique().head(20))\n",
    "\n",
    "print(\"\\nSample salesUnitGtin from products:\")\n",
    "print(df_products.select('salesUnitGtin').unique().head(20))\n",
    "\n",
    "# Check if salesUnitGtin might need leading zeros or different formatting\n",
    "print(\"\\nSalesUnitGtin data types and samples:\")\n",
    "print(df_products.select(['salesUnitGtin']).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0363d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full product data structure:\n",
      "['salesUnitGtin', 'salesUnit', 'baseUnit', 'category', 'allowedLotSize', 'deleted', 'temperatureCondition', 'vendorName', 'countryOfOrigin', 'synkkaData', 'units', 'deposits', 'substitutions']\n",
      "\n",
      "Sample product record:\n",
      "shape: (1, 13)\n",
      "┌────────────┬───────────┬──────────┬──────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
      "│ salesUnitG ┆ salesUnit ┆ baseUnit ┆ category ┆ … ┆ synkkaDat ┆ units     ┆ deposits  ┆ substitut │\n",
      "│ tin        ┆ ---       ┆ ---      ┆ ---      ┆   ┆ a         ┆ ---       ┆ ---       ┆ ions      │\n",
      "│ ---        ┆ str       ┆ str      ┆ str      ┆   ┆ ---       ┆ list[stru ┆ list[stru ┆ ---       │\n",
      "│ str        ┆           ┆          ┆          ┆   ┆ struct[26 ┆ ct[3]]    ┆ ct[3]]    ┆ list[stru │\n",
      "│            ┆           ┆          ┆          ┆   ┆ ]         ┆           ┆           ┆ ct[4]]    │\n",
      "╞════════════╪═══════════╪══════════╪══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ 6409460002 ┆ RAS       ┆ RAS      ┆ 17301    ┆ … ┆ {\"6409460 ┆ [{\"PAL\",\" ┆ []        ┆ null      │\n",
      "│ 724        ┆           ┆          ┆          ┆   ┆ 002724\",\" ┆ 640946004 ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 2025-05-2 ┆ 6902\",50. ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 0T11:02:3 ┆ 0}, {\"KI\" ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 6+0300\",\" ┆ ,\"6409460 ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 2025-09-1 ┆ 046896\",5 ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 5T09:55:5 ┆ .0}, {\"RA ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ 5+0300\",[ ┆ S\",\"64094 ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ \"246\"],[{ ┆ 60002724\" ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ \"Forssan  ┆ ,1.0}]    ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ Potato    ┆           ┆           ┆           │\n",
      "│            ┆           ┆          ┆          ┆   ┆ Sal…      ┆           ┆           ┆           │\n",
      "└────────────┴───────────┴──────────┴──────────┴───┴───────────┴───────────┴───────────┴───────────┘\n",
      "\n",
      "--- Checking nested fields ---\n",
      "\n",
      "Sample 'units' field:\n",
      "<class 'polars.series.series.Series'>\n",
      "shape: (3,)\n",
      "Series: '' [struct[3]]\n",
      "[\n",
      "\t{\"PAL\",\"6409460046902\",50.0}\n",
      "\t{\"KI\",\"6409460046896\",5.0}\n",
      "\t{\"RAS\",\"6409460002724\",1.0}\n",
      "]\n",
      "\n",
      "Sample 'synkkaData' field:\n",
      "<class 'dict'>\n",
      "{'gtin': '6409460002724', 'lastUpdated': '2025-05-20T11:02:36+0300', 'mediasLastUpdated': '2025-09-15T09:55:55+0300', 'countriesOfOrigin': ['246'], 'names': [{'value': 'Forssan Potato Salad 400g', 'language': 'en'}, {'value': 'Forssan Perunasalaatti 400g', 'language': 'fi'}, {'value': 'Forssan Potatissallad 400g', 'language': 'sv'}], 'materialAdditionalDescriptions': [], 'marketingTexts': [{'value': 'This rich potato salad is a hearty salad which is perfect for both weekday dinners and parties. Traditionally potato salad is a part of May Day festivities or New Year\\x92s celebrations. It also makes for a great side for grilled foods. The Forssa-Style Potato Salad is made with fresh mayonnaise, potatoes, tasty pickles, cucumber, and onions. You could also use this Potato Salad as a rich sandwich filling or for a sandwich cake. The Potato Salad can be customized with fresh herbs or smoked fish, ham, or why not cheese cubes! The Forssa-Style Potato Salad can niftily be brought along for a picnic or an outing in its original packaging. You should note, however, that the Potato Salad does not keep for many hours in warm weather, as it should be kept in the refrigerator like other mayonnaise-based salads.', 'language': 'en'}, {'value': 'Täyteläinen perunasalaatti on ruokaisa salaatti, joka sopii niin arkeen kuin juhlaan. Perinteisesti perunasalaatti tarjoillaan juhlapöydässä vappuna ja uutena vuotena. Se on myös mainio lisuke grilliherkkujen kylkeen. Forssan Perunasalaatti on valmistettu tuoremajoneesista, perunoista, maukkaasta säilykekurkusta, tuorekurkusta ja sipulista. Perunasalaatti sopii myös ruokaisaksi leivän täytteeksi tai vaikkapa voileipäkakun väliin. Perunasalaattia voi tuunata tuoreilla yrteillä tai savukalalla, kinkulla tai vaikkapa juustokuutioilla. Forssan perunasalaatti kulkee mainiosti mukana piknikille tai eväsretkelle alkuperäispakkauksessaan. Kannattaa kuitenkin huomioida, että perunasalaatti ei säily lämpimässä useita tunteja, vaan se tulee säilyttää jääkaapissa kuten muutkin majoneesipohjaiset salaatit.', 'language': 'fi'}, {'value': 'Denna fylliga potatissallad är en matig sallad som passar i såväl vardagen som vid fester. Potatissallad serveras traditionellt på festbordet på valborg och nyår. Den är även ett utmärkt tillbehör intill grillmaten. Forssan Potatissallad är gjord på färskmajonnäs, potatis, smakrik inlagd gurka, färsk gurka och lök. Potatissallad passar också som matigt pålägg på bröd eller till exempel i en smörgåstårta. Du kan ändra potatissalladen efter egen smak med färska örter, rökt fisk, skinka eller till exempel med tärnad ost. Forssan potatissallad går utmärkt att ta med till picknicken i sin originalförpackning. Observera dock att potatissalladen inte håller i värme i flera timmar utan måste förvaras i kylskåp, liksom andra majonnäsbaserade sallader.', 'language': 'sv'}], 'keyIngredients': [{'value': 'potato 56 % (Finland), mayonnaise (rapeseed oil, water, vinager, EGG YOLK, sugar, modified corn starch, iodised salt, preservative (potassium sorbate, sodium benzoate), maltodextrin, spices (MUSTARD SEED, white pepper)), cucumber, pickled cucumber (cucumber, flavors (incl. MUSTARD SEED), sweetener saccharin), onion', 'language': 'en'}, {'value': 'peruna 56 % (Suomi), majoneesi (rypsiöljy, vesi, etikka, KANANMUNANKELTUAINEN, sokeri, muunnettu maissitärkkelys, jodioitu suola, säilöntäaineet (kaliumsorbaatti, natriumbentsoaatti), maltodekstriini, mausteet (SINAPINSIEMEN, valkopippuri)), kurkku, säilykekurkku (kurkku, aromit (mm. SINAPINSIEMEN), makeutusaine sakariini), sipuli', 'language': 'fi'}, {'value': 'potatis 56 % (Finland), majonnäs (rypsolja, vatten, ättika, ÄGGULA, socker, modifierad majsstärkelse, joderat salt, konserveringsmedel (kaliumsorbat, natriumbensoat), maltodextrin, kryddor (SENAPSFRÖN, vitpeppar)), gurka, konserverad gurka (gurka, aromer (bl.a. SENAPSFRÖN), sötningsmedel sackarin), lök', 'language': 'sv'}], 'storageInstructions': [{'value': 'Storage temperature under +6 °C', 'language': 'en'}, {'value': 'Säilytys alle +6 °C', 'language': 'fi'}, {'value': 'Förvaring under +6 °C', 'language': 'sv'}], 'preparationInstructions': [], 'disposalInformations': [{'value': 'Sorted as plastic.', 'language': 'en'}, {'value': 'Muovi ei kuulu luontoon. Laita pakkaus muovinkeräykseen.', 'language': 'fi'}, {'value': 'Sorteras som plast.', 'language': 'sv'}], 'usageInstructions': [], 'classifications': [{'type': 'DECIMAL', 'name': 'composition', 'values': []}, {'type': 'DECIMAL', 'name': 'gda', 'values': [{'id': 'CHOAVL', 'value': 13.0, 'unit': 'GRM', 'synkkaId': None}, {'id': 'ENER-E14', 'value': 227.0, 'unit': 'E14', 'synkkaId': None}, {'id': 'ENER-KJO', 'value': 941.0, 'unit': 'KJO', 'synkkaId': None}, {'id': 'FASAT', 'value': 1.5, 'unit': 'GRM', 'synkkaId': None}, {'id': 'FAT', 'value': 19.0, 'unit': 'GRM', 'synkkaId': None}, {'id': 'FIBTG', 'value': 0.1, 'unit': 'GRM', 'synkkaId': None}, {'id': 'LACS', 'value': 0.0, 'unit': 'GRM', 'synkkaId': None}, {'id': 'PRO-', 'value': 1.4, 'unit': 'GRM', 'synkkaId': None}, {'id': 'SALTEQ', 'value': 0.55, 'unit': 'GRM', 'synkkaId': None}, {'id': 'SUGAR-', 'value': 2.7, 'unit': 'GRM', 'synkkaId': None}]}, {'type': 'DECIMAL', 'name': 'mineral', 'values': []}, {'type': 'DECIMAL', 'name': 'nutritionFact', 'values': [{'id': 'CHOAVL', 'value': 13.0, 'unit': 'GRM', 'synkkaId': None}, {'id': 'ENER-E14', 'value': 227.0, 'unit': 'E14', 'synkkaId': None}, {'id': 'ENER-KJO', 'value': 941.0, 'unit': 'KJO', 'synkkaId': None}, {'id': 'FASAT', 'value': 1.5, 'unit': 'GRM', 'synkkaId': None}, {'id': 'FAT', 'value': 19.0, 'unit': 'GRM', 'synkkaId': None}, {'id': 'FIBTG', 'value': 0.1, 'unit': 'GRM', 'synkkaId': None}, {'id': 'LACS', 'value': 0.0, 'unit': 'GRM', 'synkkaId': None}, {'id': 'PRO-', 'value': 1.4, 'unit': 'GRM', 'synkkaId': None}, {'id': 'SALTEQ', 'value': 0.55, 'unit': 'GRM', 'synkkaId': None}, {'id': 'SUGAR-', 'value': 2.7, 'unit': 'GRM', 'synkkaId': None}]}, {'type': 'DECIMAL', 'name': 'vitamin', 'values': []}, {'type': 'ENUM', 'name': 'packagingMarkedLabel', 'values': [{'id': 'GOODS_FROM_FINLAND_BLUE_SWAN', 'value': None, 'unit': None, 'synkkaId': 'GOODS_FROM_FINLAND_BLUE_SWAN'}, {'id': 'coolTemperature', 'value': None, 'unit': None, 'synkkaId': None}]}, {'type': 'ENUM', 'name': 'allergen', 'values': [{'id': 'AE', 'value': None, 'unit': 'CONTAINS', 'synkkaId': None}, {'id': 'BM', 'value': None, 'unit': 'CONTAINS', 'synkkaId': None}]}, {'type': 'ENUM', 'name': 'nonAllergen', 'values': [{'id': 'AC', 'value': None, 'unit': 'FREE_FROM', 'synkkaId': None}, {'id': 'AF', 'value': None, 'unit': 'FREE_FROM', 'synkkaId': None}, {'id': 'AM', 'value': None, 'unit': 'FREE_FROM', 'synkkaId': None}, {'id': 'AN', 'value': None, 'unit': 'FREE_FROM', 'synkkaId': None}, {'id': 'AP', 'value': None, 'unit': 'FREE_FROM', 'synkkaId': None}, {'id': 'AS', 'value': None, 'unit': 'FREE_FROM', 'synkkaId': None}, {'id': 'AU', 'value': None, 'unit': 'FREE_FROM', 'synkkaId': None}, {'id': 'AW', 'value': None, 'unit': 'FREE_FROM', 'synkkaId': None}, {'id': 'AY', 'value': None, 'unit': 'FREE_FROM', 'synkkaId': None}, {'id': 'BC', 'value': None, 'unit': 'FREE_FROM', 'synkkaId': None}, {'id': 'GB', 'value': None, 'unit': 'FREE_FROM', 'synkkaId': None}, {'id': 'GO', 'value': None, 'unit': 'FREE_FROM', 'synkkaId': None}, {'id': 'GS', 'value': None, 'unit': 'FREE_FROM', 'synkkaId': None}, {'id': 'ML', 'value': None, 'unit': 'FREE_FROM', 'synkkaId': None}, {'id': 'NL', 'value': None, 'unit': 'FREE_FROM', 'synkkaId': None}, {'id': 'NR', 'value': None, 'unit': 'FREE_FROM', 'synkkaId': None}, {'id': 'SA', 'value': None, 'unit': 'FREE_FROM', 'synkkaId': None}, {'id': 'SC', 'value': None, 'unit': 'FREE_FROM', 'synkkaId': None}, {'id': 'SH', 'value': None, 'unit': 'FREE_FROM', 'synkkaId': None}, {'id': 'ST', 'value': None, 'unit': 'FREE_FROM', 'synkkaId': None}, {'id': 'SW', 'value': None, 'unit': 'FREE_FROM', 'synkkaId': None}, {'id': 'UM', 'value': None, 'unit': 'FREE_FROM', 'synkkaId': None}, {'id': 'UW', 'value': None, 'unit': 'FREE_FROM', 'synkkaId': None}]}, {'type': 'ENUM', 'name': 'nutritionalClaim', 'values': [{'id': 'FREE_FROM_GLUTEN', 'value': None, 'unit': 'FREE_FROM', 'synkkaId': 'GLUTEN'}, {'id': 'FREE_FROM_LACTOSE', 'value': None, 'unit': 'FREE_FROM', 'synkkaId': 'LACTOSE'}, {'id': 'VEGETARIAN', 'value': None, 'unit': 'DIET', 'synkkaId': 'VEGETARIAN'}]}, {'type': 'ENUM', 'name': 'packaging', 'values': []}], 'nutritionalContent': [{'id': 'CHOAVL', 'value': 13.0, 'unit': 'GRM', 'unitPrecision': 'APPROXIMATELY', 'basisQuantity': 100.0, 'basisQuantityUnit': 'GRM', 'servingSize': 100.0, 'servingSizeUnit': 'GRM', 'dailyValueIntakePercent': None}, {'id': 'ENER-E14', 'value': 227.0, 'unit': 'E14', 'unitPrecision': 'APPROXIMATELY', 'basisQuantity': 100.0, 'basisQuantityUnit': 'GRM', 'servingSize': 100.0, 'servingSizeUnit': 'GRM', 'dailyValueIntakePercent': None}, {'id': 'ENER-KJO', 'value': 941.0, 'unit': 'KJO', 'unitPrecision': 'APPROXIMATELY', 'basisQuantity': 100.0, 'basisQuantityUnit': 'GRM', 'servingSize': 100.0, 'servingSizeUnit': 'GRM', 'dailyValueIntakePercent': None}, {'id': 'FASAT', 'value': 1.5, 'unit': 'GRM', 'unitPrecision': 'APPROXIMATELY', 'basisQuantity': 100.0, 'basisQuantityUnit': 'GRM', 'servingSize': 100.0, 'servingSizeUnit': 'GRM', 'dailyValueIntakePercent': None}, {'id': 'FAT', 'value': 19.0, 'unit': 'GRM', 'unitPrecision': 'APPROXIMATELY', 'basisQuantity': 100.0, 'basisQuantityUnit': 'GRM', 'servingSize': 100.0, 'servingSizeUnit': 'GRM', 'dailyValueIntakePercent': None}, {'id': 'FIBTG', 'value': 0.1, 'unit': 'GRM', 'unitPrecision': 'APPROXIMATELY', 'basisQuantity': 100.0, 'basisQuantityUnit': 'GRM', 'servingSize': 100.0, 'servingSizeUnit': 'GRM', 'dailyValueIntakePercent': None}, {'id': 'LACS', 'value': 0.0, 'unit': 'GRM', 'unitPrecision': 'APPROXIMATELY', 'basisQuantity': 100.0, 'basisQuantityUnit': 'GRM', 'servingSize': 100.0, 'servingSizeUnit': 'GRM', 'dailyValueIntakePercent': None}, {'id': 'PRO-', 'value': 1.4, 'unit': 'GRM', 'unitPrecision': 'APPROXIMATELY', 'basisQuantity': 100.0, 'basisQuantityUnit': 'GRM', 'servingSize': 100.0, 'servingSizeUnit': 'GRM', 'dailyValueIntakePercent': None}, {'id': 'SALTEQ', 'value': 0.55, 'unit': 'GRM', 'unitPrecision': 'APPROXIMATELY', 'basisQuantity': 100.0, 'basisQuantityUnit': 'GRM', 'servingSize': 100.0, 'servingSizeUnit': 'GRM', 'dailyValueIntakePercent': None}, {'id': 'SUGAR-', 'value': 2.7, 'unit': 'GRM', 'unitPrecision': 'APPROXIMATELY', 'basisQuantity': 100.0, 'basisQuantityUnit': 'GRM', 'servingSize': 100.0, 'servingSizeUnit': 'GRM', 'dailyValueIntakePercent': None}], 'ingredients': [{'sequence': 1, 'percentage': 56.0, 'names': [{'value': 'potato', 'language': 'en'}, {'value': 'Peruna', 'language': 'fi'}, {'value': 'potatis', 'language': 'sv'}], 'origins': [{'type': 'FARMING', 'country': '246'}]}], 'medias': [{'id': 52633, 'primary': True}], 'children': [], 'fishingReports': [], 'safetyData': [], 'brand': 'Forssan', 'variableUnit': False, 'vatCode': 'MEDIUM', 'producers': [{'id': '6407809999995', 'name': 'Atria Suomi Oy'}], 'unitConversions': [{'synkkaPackagingType': 'BASE_UNIT_OR_EACH', 'width': {'unit': 'MMT', 'value': 166.0}, 'length': {'unit': 'MMT', 'value': 50.0}, 'height': {'unit': 'MMT', 'value': 101.0}, 'volume': {'unit': 'KGM', 'value': 0.4}, 'netWeight': {'unit': 'KGM', 'value': 0.4}, 'grossWeight': {'unit': 'GRM', 'value': 423.0}}], 'minTemperature': 5.0, 'maxTemperature': 8.0}\n",
      "\n",
      "Sample 'substitutions' field:\n",
      "<class 'NoneType'>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Let's examine the full structure of product data to find a mapping\n",
    "print(\"Full product data structure:\")\n",
    "print(df_products.columns)\n",
    "print(\"\\nSample product record:\")\n",
    "print(df_products.head(1))\n",
    "\n",
    "# Check if there's a nested structure that might contain product_code\n",
    "print(\"\\n--- Checking nested fields ---\")\n",
    "\n",
    "# Check 'units' field\n",
    "if 'units' in df_products.columns:\n",
    "    print(\"\\nSample 'units' field:\")\n",
    "    sample_units = df_products['units'][0]\n",
    "    print(type(sample_units))\n",
    "    print(sample_units)\n",
    "\n",
    "# Check 'synkkaData' field\n",
    "if 'synkkaData' in df_products.columns:\n",
    "    print(\"\\nSample 'synkkaData' field:\")\n",
    "    sample_synkka = df_products['synkkaData'][0]\n",
    "    print(type(sample_synkka))\n",
    "    print(sample_synkka)\n",
    "\n",
    "# Check 'substitutions' field\n",
    "if 'substitutions' in df_products.columns:\n",
    "    print(\"\\nSample 'substitutions' field:\")\n",
    "    sample_sub = df_products['substitutions'][0]\n",
    "    print(type(sample_sub))\n",
    "    print(sample_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8f0dbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04c81757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FIXING ORDER HOUR EXTRACTION\n",
      "================================================================================\n",
      "✓ Added order_hour feature\n",
      "Sample order_hour values: [16, 15, 20, 13, 14, 12, 23, 9, 13, 16]\n",
      "\n",
      "================================================================================\n",
      "PREPARING DATA FOR MODELING\n",
      "================================================================================\n",
      "\n",
      "Selected 26 features:\n",
      "   1. order_qty\n",
      "   2. picking_picked_qty\n",
      "   3. order_day_of_week\n",
      "   4. order_day_of_month\n",
      "   5. order_month\n",
      "   6. order_quarter\n",
      "   7. is_weekend\n",
      "   8. lead_time_days\n",
      "   9. order_hour\n",
      "  10. product_shortage_rate\n",
      "  11. product_avg_order_qty\n",
      "  12. product_order_qty_std\n",
      "  13. product_order_count\n",
      "  14. customer_shortage_rate\n",
      "  15. customer_total_order_qty\n",
      "  16. customer_order_count\n",
      "  17. customer_avg_lead_time\n",
      "  18. customer_product_shortage_rate\n",
      "  19. customer_product_order_count\n",
      "  20. vendor_shortage_rate\n",
      "  21. vendor_order_count\n",
      "  22. plant_shortage_rate\n",
      "  23. storage_shortage_rate\n",
      "  24. replacement_frequency\n",
      "  25. category_shortage_rate\n",
      "  26. temp_condition_shortage_rate\n",
      "\n",
      "Rows before null removal: 7,350,226\n",
      "Rows after null removal: 7,349,594\n",
      "\n",
      "✓ No nulls in features\n",
      "\n",
      "--- Class Balance ---\n",
      "Shortage rate: 3.98%\n",
      "Non-shortage rate: 96.02%\n",
      "Class imbalance ratio: 24.2:1\n",
      "\n",
      "--- Creating Time-Based Train/Test Split ---\n",
      "\n",
      "Training set: 5,879,675 rows\n",
      "  Date range: 2024-09-01 to 2025-07-22\n",
      "  Shortage rate: 3.33%\n",
      "\n",
      "Test set: 1,469,919 rows\n",
      "  Date range: 2025-07-22 to 2025-09-30\n",
      "  Shortage rate: 6.57%\n",
      "\n",
      "✓ Data prepared for modeling!\n",
      "X_train shape: (5879675, 26)\n",
      "X_test shape: (1469919, 26)\n",
      "\n",
      "================================================================================\n",
      "MODEL 1: LOGISTIC REGRESSION (Baseline)\n",
      "================================================================================\n",
      "Training time: 538.5s\n",
      "\n",
      "================================================================================\n",
      "Logistic Regression PERFORMANCE\n",
      "================================================================================\n",
      "\n",
      "Metrics:\n",
      "  Accuracy:  0.7777\n",
      "  Precision: 0.1934 (% of predicted shortages that were correct)\n",
      "  Recall:    0.7514 (% of actual shortages we caught)\n",
      "  F1-Score:  0.3076 (harmonic mean)\n",
      "  ROC AUC:   0.8214\n",
      "\n",
      "Confusion Matrix:\n",
      "                     Predicted: No | Predicted: Yes\n",
      "Actual: No Shortage   1,070,502   |      302,801\n",
      "Actual: Shortage         24,014   |       72,602\n",
      "\n",
      "Business Impact:\n",
      "  • Actual shortages: 96,616\n",
      "  • Predicted shortages: 375,403\n",
      "  • Caught 72,602 shortages (75.1%)\n",
      "  • Missed 24,014 shortages (24.9%)\n",
      "  • False alarms: 302,801\n",
      "\n",
      "================================================================================\n",
      "MODEL 2: RANDOM FOREST\n",
      "================================================================================\n",
      "Training time: 372.5s\n",
      "\n",
      "================================================================================\n",
      "Random Forest PERFORMANCE\n",
      "================================================================================\n",
      "\n",
      "Metrics:\n",
      "  Accuracy:  0.9245\n",
      "  Precision: 0.4648 (% of predicted shortages that were correct)\n",
      "  Recall:    0.9865 (% of actual shortages we caught)\n",
      "  F1-Score:  0.6319 (harmonic mean)\n",
      "  ROC AUC:   0.9939\n",
      "\n",
      "Confusion Matrix:\n",
      "                     Predicted: No | Predicted: Yes\n",
      "Actual: No Shortage   1,263,571   |      109,732\n",
      "Actual: Shortage          1,303   |       95,313\n",
      "\n",
      "Business Impact:\n",
      "  • Actual shortages: 96,616\n",
      "  • Predicted shortages: 205,045\n",
      "  • Caught 95,313 shortages (98.7%)\n",
      "  • Missed 1,303 shortages (1.3%)\n",
      "  • False alarms: 109,732\n",
      "\n",
      "🌟 Top 15 Most Important Features:\n",
      "  customer_product_shortage_rate............... 0.4097\n",
      "  picking_picked_qty........................... 0.1809\n",
      "  product_shortage_rate........................ 0.1691\n",
      "  storage_shortage_rate........................ 0.0876\n",
      "  plant_shortage_rate.......................... 0.0601\n",
      "  order_qty.................................... 0.0263\n",
      "  customer_shortage_rate....................... 0.0123\n",
      "  product_order_count.......................... 0.0107\n",
      "  product_avg_order_qty........................ 0.0107\n",
      "  product_order_qty_std........................ 0.0101\n",
      "  replacement_frequency........................ 0.0095\n",
      "  customer_product_order_count................. 0.0054\n",
      "  customer_avg_lead_time....................... 0.0031\n",
      "  customer_order_count......................... 0.0012\n",
      "  lead_time_days............................... 0.0010\n",
      "\n",
      "================================================================================\n",
      "MODEL 3: XGBOOST (Advanced)\n",
      "================================================================================\n",
      "Scale pos weight: 29.1\n",
      "Training time: 57.5s\n",
      "\n",
      "================================================================================\n",
      "XGBoost PERFORMANCE\n",
      "================================================================================\n",
      "\n",
      "Metrics:\n",
      "  Accuracy:  0.9758\n",
      "  Precision: 0.7345 (% of predicted shortages that were correct)\n",
      "  Recall:    0.9887 (% of actual shortages we caught)\n",
      "  F1-Score:  0.8429 (harmonic mean)\n",
      "  ROC AUC:   0.9986\n",
      "\n",
      "Confusion Matrix:\n",
      "                     Predicted: No | Predicted: Yes\n",
      "Actual: No Shortage   1,338,778   |       34,525\n",
      "Actual: Shortage          1,092   |       95,524\n",
      "\n",
      "Business Impact:\n",
      "  • Actual shortages: 96,616\n",
      "  • Predicted shortages: 130,049\n",
      "  • Caught 95,524 shortages (98.9%)\n",
      "  • Missed 1,092 shortages (1.1%)\n",
      "  • False alarms: 34,525\n",
      "\n",
      "🌟 Top 15 Most Important Features (XGBoost):\n",
      "  customer_product_shortage_rate............... 0.5720\n",
      "  plant_shortage_rate.......................... 0.0801\n",
      "  picking_picked_qty........................... 0.0789\n",
      "  product_shortage_rate........................ 0.0730\n",
      "  storage_shortage_rate........................ 0.0696\n",
      "  order_qty.................................... 0.0581\n",
      "  customer_shortage_rate....................... 0.0126\n",
      "  customer_product_order_count................. 0.0092\n",
      "  product_order_count.......................... 0.0087\n",
      "  customer_avg_lead_time....................... 0.0070\n",
      "  product_order_qty_std........................ 0.0060\n",
      "  replacement_frequency........................ 0.0043\n",
      "  order_month.................................. 0.0039\n",
      "  order_quarter................................ 0.0036\n",
      "  product_avg_order_qty........................ 0.0026\n",
      "\n",
      "================================================================================\n",
      "📊 MODEL COMPARISON\n",
      "================================================================================\n",
      "\n",
      "              Model  Accuracy  Precision   Recall       F1  ROC-AUC\n",
      "Logistic Regression  0.777665   0.193397 0.751449 0.307623 0.821359\n",
      "      Random Forest  0.924462   0.464839 0.986514 0.631921 0.993915\n",
      "            XGBoost  0.975769   0.734523 0.988698 0.842865 0.998602\n",
      "\n",
      "================================================================================\n",
      "💾 SAVING MODEL\n",
      "================================================================================\n",
      "✓ Saved: shortage_predictor_model.pkl\n",
      "✓ Saved: test_predictions.parquet\n",
      "\n",
      "✅ Modeling complete!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import time\n",
    "\n",
    "# Fix order_hour extraction\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FIXING ORDER HOUR EXTRACTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_features = df_features.with_columns([\n",
    "    (pl.col('order_created_time') // 10000).alias('order_hour')\n",
    "])\n",
    "print(\"✓ Added order_hour feature\")\n",
    "print(f\"Sample order_hour values: {df_features['order_hour'].head(10).to_list()}\")\n",
    "\n",
    "# Prepare data for modeling\n",
    "def prepare_modeling_data(df):\n",
    "    \"\"\"Prepare data for machine learning\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PREPARING DATA FOR MODELING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Select features for modeling\n",
    "    feature_cols = [\n",
    "        # Quantity features\n",
    "        'order_qty',\n",
    "        'picking_picked_qty',\n",
    "        \n",
    "        # Date features\n",
    "        'order_day_of_week',\n",
    "        'order_day_of_month',\n",
    "        'order_month',\n",
    "        'order_quarter',\n",
    "        'is_weekend',\n",
    "        'lead_time_days',\n",
    "        'order_hour',\n",
    "        \n",
    "        # Product features\n",
    "        'product_shortage_rate',\n",
    "        'product_avg_order_qty',\n",
    "        'product_order_qty_std',\n",
    "        'product_order_count',\n",
    "        \n",
    "        # Customer features\n",
    "        'customer_shortage_rate',\n",
    "        'customer_total_order_qty',\n",
    "        'customer_order_count',\n",
    "        'customer_avg_lead_time',\n",
    "        \n",
    "        # Customer-Product features\n",
    "        'customer_product_shortage_rate',\n",
    "        'customer_product_order_count',\n",
    "        \n",
    "        # Vendor features (all UNKNOWN but keeping structure)\n",
    "        'vendor_shortage_rate',\n",
    "        'vendor_order_count',\n",
    "        \n",
    "        # Location features\n",
    "        'plant_shortage_rate',\n",
    "        'storage_shortage_rate',\n",
    "        \n",
    "        # Replacement features\n",
    "        'replacement_frequency',\n",
    "        \n",
    "        # Category features\n",
    "        'category_shortage_rate',\n",
    "        'temp_condition_shortage_rate'\n",
    "    ]\n",
    "    \n",
    "    # Filter to only columns that exist\n",
    "    feature_cols = [col for col in feature_cols if col in df.columns]\n",
    "    \n",
    "    print(f\"\\nSelected {len(feature_cols)} features:\")\n",
    "    for i, col in enumerate(feature_cols, 1):\n",
    "        print(f\"  {i:2d}. {col}\")\n",
    "    \n",
    "    # Add target and metadata\n",
    "    cols_to_keep = feature_cols + ['is_shortage', 'order_created_date', 'order_number', 'product_code', 'customer_number']\n",
    "    cols_to_keep = [col for col in cols_to_keep if col in df.columns]\n",
    "    \n",
    "    df_model = df.select(cols_to_keep)\n",
    "    \n",
    "    # Remove rows with nulls in features\n",
    "    print(f\"\\nRows before null removal: {df_model.height:,}\")\n",
    "    df_model = df_model.drop_nulls(subset=feature_cols)\n",
    "    print(f\"Rows after null removal: {df_model.height:,}\")\n",
    "    \n",
    "    # Check for any remaining nulls\n",
    "    null_counts = df_model.select(feature_cols).null_count()\n",
    "    total_nulls = sum(null_counts.row(0))\n",
    "    \n",
    "    if total_nulls > 0:\n",
    "        print(f\"\\n⚠ Warning: {total_nulls} nulls remain\")\n",
    "    else:\n",
    "        print(\"\\n✓ No nulls in features\")\n",
    "    \n",
    "    # Check class balance\n",
    "    print(\"\\n--- Class Balance ---\")\n",
    "    shortage_rate = df_model['is_shortage'].mean()\n",
    "    print(f\"Shortage rate: {shortage_rate*100:.2f}%\")\n",
    "    print(f\"Non-shortage rate: {(1-shortage_rate)*100:.2f}%\")\n",
    "    print(f\"Class imbalance ratio: {(1-shortage_rate)/shortage_rate:.1f}:1\")\n",
    "    \n",
    "    # Time-based split\n",
    "    print(\"\\n--- Creating Time-Based Train/Test Split ---\")\n",
    "    df_model = df_model.sort('order_created_date')\n",
    "    \n",
    "    # Use 80% for training, 20% for testing\n",
    "    split_idx = int(df_model.height * 0.8)\n",
    "    \n",
    "    df_train = df_model[:split_idx]\n",
    "    df_test = df_model[split_idx:]\n",
    "    \n",
    "    print(f\"\\nTraining set: {df_train.height:,} rows\")\n",
    "    print(f\"  Date range: {df_train['order_created_date'].min()} to {df_train['order_created_date'].max()}\")\n",
    "    print(f\"  Shortage rate: {df_train['is_shortage'].mean()*100:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nTest set: {df_test.height:,} rows\")\n",
    "    print(f\"  Date range: {df_test['order_created_date'].min()} to {df_test['order_created_date'].max()}\")\n",
    "    print(f\"  Shortage rate: {df_test['is_shortage'].mean()*100:.2f}%\")\n",
    "    \n",
    "    # Convert to numpy for sklearn\n",
    "    X_train = df_train.select(feature_cols).to_numpy()\n",
    "    y_train = df_train.select('is_shortage').to_numpy().ravel()\n",
    "    \n",
    "    X_test = df_test.select(feature_cols).to_numpy()\n",
    "    y_test = df_test.select('is_shortage').to_numpy().ravel()\n",
    "    \n",
    "    print(f\"\\n✓ Data prepared for modeling!\")\n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, feature_cols, df_train, df_test\n",
    "\n",
    "X_train, X_test, y_train, y_test, feature_cols, df_train, df_test = prepare_modeling_data(df_features)\n",
    "\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(y_true, y_pred, y_pred_proba, model_name):\n",
    "    \"\"\"Evaluate model performance\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{model_name} PERFORMANCE\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    accuracy = (y_true == y_pred).mean()\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    print(f\"\\nMetrics:\")\n",
    "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f} (% of predicted shortages that were correct)\")\n",
    "    print(f\"  Recall:    {recall:.4f} (% of actual shortages we caught)\")\n",
    "    print(f\"  F1-Score:  {f1:.4f} (harmonic mean)\")\n",
    "    \n",
    "    try:\n",
    "        roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "        print(f\"  ROC AUC:   {roc_auc:.4f}\")\n",
    "    except:\n",
    "        roc_auc = None\n",
    "        print(f\"  ROC AUC:   N/A\")\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"{'':20} Predicted: No | Predicted: Yes\")\n",
    "    print(f\"Actual: No Shortage  {cm[0,0]:>10,}   |   {cm[0,1]:>10,}\")\n",
    "    print(f\"Actual: Shortage     {cm[1,0]:>10,}   |   {cm[1,1]:>10,}\")\n",
    "    \n",
    "    total_actual = cm[1,0] + cm[1,1]\n",
    "    total_predicted = cm[0,1] + cm[1,1]\n",
    "    \n",
    "    print(f\"\\nBusiness Impact:\")\n",
    "    print(f\"  • Actual shortages: {total_actual:,}\")\n",
    "    print(f\"  • Predicted shortages: {total_predicted:,}\")\n",
    "    print(f\"  • Caught {cm[1,1]:,} shortages ({cm[1,1]/total_actual*100:.1f}%)\")\n",
    "    print(f\"  • Missed {cm[1,0]:,} shortages ({cm[1,0]/total_actual*100:.1f}%)\")\n",
    "    print(f\"  • False alarms: {cm[0,1]:,}\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "\n",
    "# MODEL 1: Logistic Regression\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL 1: LOGISTIC REGRESSION (Baseline)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "start = time.time()\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced', n_jobs=-1)\n",
    "lr_model.fit(X_train, y_train)\n",
    "print(f\"Training time: {time.time()-start:.1f}s\")\n",
    "\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "y_pred_proba_lr = lr_model.predict_proba(X_test)[:, 1]\n",
    "lr_metrics = evaluate_model(y_test, y_pred_lr, y_pred_proba_lr, \"Logistic Regression\")\n",
    "\n",
    "\n",
    "# MODEL 2: Random Forest\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL 2: RANDOM FOREST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "start = time.time()\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=100,\n",
    "    min_samples_leaf=50,\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(f\"Training time: {time.time()-start:.1f}s\")\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_pred_proba_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "rf_metrics = evaluate_model(y_test, y_pred_rf, y_pred_proba_rf, \"Random Forest\")\n",
    "\n",
    "print(\"\\n🌟 Top 15 Most Important Features:\")\n",
    "feat_imp = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "for i, row in feat_imp.head(15).iterrows():\n",
    "    print(f\"  {row['feature']:.<45} {row['importance']:.4f}\")\n",
    "\n",
    "\n",
    "# MODEL 3: XGBoost\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL 3: XGBOOST (Advanced)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"Scale pos weight: {scale_pos_weight:.1f}\")\n",
    "\n",
    "start = time.time()\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print(f\"Training time: {time.time()-start:.1f}s\")\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "y_pred_proba_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
    "xgb_metrics = evaluate_model(y_test, y_pred_xgb, y_pred_proba_xgb, \"XGBoost\")\n",
    "\n",
    "print(\"\\n🌟 Top 15 Most Important Features (XGBoost):\")\n",
    "feat_imp_xgb = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "for i, row in feat_imp_xgb.head(15).iterrows():\n",
    "    print(f\"  {row['feature']:.<45} {row['importance']:.4f}\")\n",
    "\n",
    "\n",
    "# COMPARISON\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📊 MODEL COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'XGBoost'],\n",
    "    'Accuracy': [lr_metrics['accuracy'], rf_metrics['accuracy'], xgb_metrics['accuracy']],\n",
    "    'Precision': [lr_metrics['precision'], rf_metrics['precision'], xgb_metrics['precision']],\n",
    "    'Recall': [lr_metrics['recall'], rf_metrics['recall'], xgb_metrics['recall']],\n",
    "    'F1': [lr_metrics['f1'], rf_metrics['f1'], xgb_metrics['f1']],\n",
    "    'ROC-AUC': [lr_metrics.get('roc_auc', 0), rf_metrics.get('roc_auc', 0), xgb_metrics.get('roc_auc', 0)]\n",
    "})\n",
    "print(\"\\n\" + comparison.to_string(index=False))\n",
    "\n",
    "# Save best model\n",
    "import pickle\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"💾 SAVING MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "best_model = xgb_model\n",
    "artifacts = {\n",
    "    'model': best_model,\n",
    "    'feature_cols': feature_cols,\n",
    "    'feature_importance': feat_imp_xgb,\n",
    "    'threshold': 0.5  # Can be tuned later\n",
    "}\n",
    "\n",
    "with open('shortage_predictor_model.pkl', 'wb') as f:\n",
    "    pickle.dump(artifacts, f)\n",
    "print(\"✓ Saved: shortage_predictor_model.pkl\")\n",
    "\n",
    "# Save processed test data\n",
    "df_test_with_pred = df_test.with_columns([\n",
    "    pl.lit(y_pred_xgb).alias('predicted_shortage'),\n",
    "    pl.lit(y_pred_proba_xgb).alias('shortage_probability')\n",
    "])\n",
    "df_test_with_pred.write_parquet('test_predictions.parquet')\n",
    "print(\"✓ Saved: test_predictions.parquet\")\n",
    "\n",
    "print(\"\\n✅ Modeling complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "046ff6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "✓ Model loaded with 26 features\n",
      "\n",
      "Loading historical statistics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mfrfo\\AppData\\Local\\Temp\\ipykernel_77616\\2976920318.py:80: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias('replacement_frequency')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Historical statistics loaded\n",
      "\n",
      "✅ Predictor ready!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "class ShortagePredictor:\n",
    "    \"\"\"Pipeline for predicting order shortages\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path='shortage_predictor_model.pkl'):\n",
    "        \"\"\"Load the trained model\"\"\"\n",
    "        print(\"Loading model...\")\n",
    "        with open(model_path, 'rb') as f:\n",
    "            artifacts = pickle.load(f)\n",
    "        \n",
    "        self.model = artifacts['model']\n",
    "        self.feature_cols = artifacts['feature_cols']\n",
    "        self.feature_importance = artifacts['feature_importance']\n",
    "        self.threshold = artifacts.get('threshold', 0.5)\n",
    "        \n",
    "        print(f\"✓ Model loaded with {len(self.feature_cols)} features\")\n",
    "        \n",
    "        # Store historical aggregations for feature engineering\n",
    "        self.historical_stats = None\n",
    "    \n",
    "    def load_historical_data(self, df_features):\n",
    "        \"\"\"\n",
    "        Load and store historical statistics for feature engineering\n",
    "        This should be called once with your historical data\n",
    "        \"\"\"\n",
    "        print(\"\\nLoading historical statistics...\")\n",
    "        \n",
    "        # Product stats\n",
    "        self.product_stats = df_features.group_by('product_code').agg([\n",
    "            pl.col('is_shortage').mean().alias('product_shortage_rate'),\n",
    "            pl.col('order_qty').mean().alias('product_avg_order_qty'),\n",
    "            pl.col('order_qty').std().alias('product_order_qty_std'),\n",
    "            pl.col('order_number').n_unique().alias('product_order_count')\n",
    "        ])\n",
    "        \n",
    "        # Customer stats\n",
    "        self.customer_stats = df_features.group_by('customer_number').agg([\n",
    "            pl.col('is_shortage').mean().alias('customer_shortage_rate'),\n",
    "            pl.col('order_qty').sum().alias('customer_total_order_qty'),\n",
    "            pl.col('order_number').n_unique().alias('customer_order_count'),\n",
    "            pl.col('lead_time_days').mean().alias('customer_avg_lead_time')\n",
    "        ])\n",
    "        \n",
    "        # Customer-Product stats\n",
    "        self.customer_product_stats = df_features.group_by(['customer_number', 'product_code']).agg([\n",
    "            pl.col('is_shortage').mean().alias('customer_product_shortage_rate'),\n",
    "            pl.col('order_number').n_unique().alias('customer_product_order_count')\n",
    "        ])\n",
    "        \n",
    "        # Location stats\n",
    "        self.plant_stats = df_features.group_by('plant').agg([\n",
    "            pl.col('is_shortage').mean().alias('plant_shortage_rate')\n",
    "        ])\n",
    "        \n",
    "        self.storage_stats = df_features.group_by('storage_location').agg([\n",
    "            pl.col('is_shortage').mean().alias('storage_shortage_rate')\n",
    "        ])\n",
    "        \n",
    "        # Category stats (all UNKNOWN but keep for structure)\n",
    "        self.category_stats = df_features.group_by('category').agg([\n",
    "            pl.col('is_shortage').mean().alias('category_shortage_rate')\n",
    "        ])\n",
    "        \n",
    "        self.temp_stats = df_features.group_by('temperatureCondition').agg([\n",
    "            pl.col('is_shortage').mean().alias('temp_condition_shortage_rate')\n",
    "        ])\n",
    "        \n",
    "        # Vendor stats\n",
    "        self.vendor_stats = df_features.group_by('vendorName').agg([\n",
    "            pl.col('is_shortage').mean().alias('vendor_shortage_rate'),\n",
    "            pl.col('order_number').n_unique().alias('vendor_order_count')\n",
    "        ])\n",
    "        \n",
    "        # Replacement stats\n",
    "        self.replacement_stats = df_features.group_by('product_code').agg([\n",
    "            pl.count().alias('replacement_frequency')\n",
    "        ])\n",
    "        \n",
    "        print(\"✓ Historical statistics loaded\")\n",
    "    \n",
    "    def engineer_features(self, df_new_orders):\n",
    "        \"\"\"\n",
    "        Engineer features for new orders\n",
    "        df_new_orders should have columns: order_number, order_created_date, order_created_time,\n",
    "        requested_delivery_date, customer_number, product_code, order_qty, plant, storage_location, etc.\n",
    "        \"\"\"\n",
    "        df = df_new_orders.clone()\n",
    "        \n",
    "        # Date features\n",
    "        df = df.with_columns([\n",
    "            pl.col('order_created_date').dt.weekday().alias('order_day_of_week'),\n",
    "            pl.col('order_created_date').dt.day().alias('order_day_of_month'),\n",
    "            pl.col('order_created_date').dt.month().alias('order_month'),\n",
    "            pl.col('order_created_date').dt.quarter().alias('order_quarter'),\n",
    "            (pl.col('order_created_date').dt.weekday() >= 5).cast(pl.Int8).alias('is_weekend'),\n",
    "            ((pl.col('requested_delivery_date') - pl.col('order_created_date')).dt.total_days()).alias('lead_time_days'),\n",
    "            (pl.col('order_created_time') // 10000).alias('order_hour')\n",
    "        ])\n",
    "        \n",
    "        # Add picking_picked_qty (for new orders, we don't have this yet, so use 0 or order_qty as estimate)\n",
    "        if 'picking_picked_qty' not in df.columns:\n",
    "            df = df.with_columns([\n",
    "                pl.lit(0).alias('picking_picked_qty')  # Default to 0 for new orders\n",
    "            ])\n",
    "        \n",
    "        # Join with historical stats\n",
    "        df = df.join(self.product_stats, on='product_code', how='left')\n",
    "        df = df.join(self.customer_stats, on='customer_number', how='left')\n",
    "        df = df.join(self.customer_product_stats, on=['customer_number', 'product_code'], how='left')\n",
    "        df = df.join(self.plant_stats, on='plant', how='left')\n",
    "        df = df.join(self.storage_stats, on='storage_location', how='left')\n",
    "        \n",
    "        # Handle nulls (new customers/products)\n",
    "        df = df.with_columns([\n",
    "            pl.col('product_shortage_rate').fill_null(0.04),  # Use global average\n",
    "            pl.col('product_avg_order_qty').fill_null(pl.col('order_qty')),\n",
    "            pl.col('product_order_qty_std').fill_null(0),\n",
    "            pl.col('product_order_count').fill_null(0),\n",
    "            pl.col('customer_shortage_rate').fill_null(0.04),\n",
    "            pl.col('customer_total_order_qty').fill_null(0),\n",
    "            pl.col('customer_order_count').fill_null(0),\n",
    "            pl.col('customer_avg_lead_time').fill_null(pl.col('lead_time_days')),\n",
    "            pl.col('customer_product_shortage_rate').fill_null(0.04),\n",
    "            pl.col('customer_product_order_count').fill_null(0),\n",
    "            pl.col('plant_shortage_rate').fill_null(0.04),\n",
    "            pl.col('storage_shortage_rate').fill_null(0.04)\n",
    "        ])\n",
    "        \n",
    "        # Add remaining features with defaults\n",
    "        if 'vendorName' in df.columns:\n",
    "            df = df.join(self.vendor_stats, on='vendorName', how='left')\n",
    "        \n",
    "        df = df.with_columns([\n",
    "            pl.lit(0.04).alias('vendor_shortage_rate') if 'vendor_shortage_rate' not in df.columns else pl.col('vendor_shortage_rate').fill_null(0.04),\n",
    "            pl.lit(0).alias('vendor_order_count') if 'vendor_order_count' not in df.columns else pl.col('vendor_order_count').fill_null(0),\n",
    "            pl.lit(0).alias('replacement_frequency') if 'replacement_frequency' not in df.columns else pl.col('replacement_frequency').fill_null(0),\n",
    "            pl.lit(0.04).alias('category_shortage_rate') if 'category_shortage_rate' not in df.columns else pl.col('category_shortage_rate').fill_null(0.04),\n",
    "            pl.lit(0.04).alias('temp_condition_shortage_rate') if 'temp_condition_shortage_rate' not in df.columns else pl.col('temp_condition_shortage_rate').fill_null(0.04)\n",
    "        ])\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def predict(self, df_new_orders):\n",
    "        \"\"\"\n",
    "        Predict shortages for new orders\n",
    "        Returns DataFrame with predictions and probabilities\n",
    "        \"\"\"\n",
    "        print(f\"\\nPredicting shortages for {df_new_orders.height} orders...\")\n",
    "        \n",
    "        # Engineer features\n",
    "        df_features = self.engineer_features(df_new_orders)\n",
    "        \n",
    "        # Select only the features used in training\n",
    "        X = df_features.select(self.feature_cols).to_numpy()\n",
    "        \n",
    "        # Predict\n",
    "        predictions = self.model.predict(X)\n",
    "        probabilities = self.model.predict_proba(X)[:, 1]\n",
    "        \n",
    "        # Add predictions to dataframe\n",
    "        df_result = df_features.with_columns([\n",
    "            pl.lit(predictions).alias('predicted_shortage'),\n",
    "            pl.lit(probabilities).alias('shortage_probability')\n",
    "        ])\n",
    "        \n",
    "        shortage_count = predictions.sum()\n",
    "        print(f\"✓ Predicted {shortage_count} shortages ({shortage_count/len(predictions)*100:.1f}%)\")\n",
    "        \n",
    "        return df_result\n",
    "    \n",
    "    def get_high_risk_orders(self, df_predictions, threshold=0.7):\n",
    "        \"\"\"Get orders with high shortage risk\"\"\"\n",
    "        high_risk = df_predictions.filter(\n",
    "            pl.col('shortage_probability') >= threshold\n",
    "        ).sort('shortage_probability', descending=True)\n",
    "        \n",
    "        return high_risk\n",
    "    \n",
    "    def explain_prediction(self, df_row):\n",
    "        \"\"\"Explain why an order was predicted as shortage\"\"\"\n",
    "        features = df_row.select(self.feature_cols).to_numpy()[0]\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"SHORTAGE RISK EXPLANATION\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"\\nOrder: {df_row['order_number'][0]}\")\n",
    "        print(f\"Product: {df_row['product_code'][0]}\")\n",
    "        print(f\"Customer: {df_row['customer_number'][0]}\")\n",
    "        print(f\"Shortage Probability: {df_row['shortage_probability'][0]:.1%}\")\n",
    "        \n",
    "        print(\"\\nTop Risk Factors:\")\n",
    "        # Get feature contributions\n",
    "        feature_values = {}\n",
    "        for i, col in enumerate(self.feature_cols):\n",
    "            importance = self.feature_importance[\n",
    "                self.feature_importance['feature'] == col\n",
    "            ]['importance'].values[0] if col in self.feature_importance['feature'].values else 0\n",
    "            \n",
    "            feature_values[col] = {\n",
    "                'value': features[i],\n",
    "                'importance': importance,\n",
    "                'contribution': features[i] * importance\n",
    "            }\n",
    "        \n",
    "        # Sort by contribution\n",
    "        sorted_features = sorted(feature_values.items(), \n",
    "                                key=lambda x: abs(x[1]['contribution']), \n",
    "                                reverse=True)\n",
    "        \n",
    "        for i, (feat, info) in enumerate(sorted_features[:10], 1):\n",
    "            print(f\"  {i:2d}. {feat:.<40} {info['value']:.4f}\")\n",
    "\n",
    "# Initialize predictor\n",
    "predictor = ShortagePredictor('shortage_predictor_model.pkl')\n",
    "\n",
    "# Load historical data for feature engineering\n",
    "predictor.load_historical_data(df_features)\n",
    "\n",
    "print(\"\\n✅ Predictor ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ac648f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXAMPLE: PREDICTING ON NEW ORDERS\n",
      "================================================================================\n",
      "Available columns in df_test:\n",
      "['order_qty', 'picking_picked_qty', 'order_day_of_week', 'order_day_of_month', 'order_month', 'order_quarter', 'is_weekend', 'lead_time_days', 'order_hour', 'product_shortage_rate', 'product_avg_order_qty', 'product_order_qty_std', 'product_order_count', 'customer_shortage_rate', 'customer_total_order_qty', 'customer_order_count', 'customer_avg_lead_time', 'customer_product_shortage_rate', 'customer_product_order_count', 'vendor_shortage_rate', 'vendor_order_count', 'plant_shortage_rate', 'storage_shortage_rate', 'replacement_frequency', 'category_shortage_rate', 'temp_condition_shortage_rate', 'is_shortage', 'order_created_date', 'order_number', 'product_code', 'customer_number']\n",
      "\n",
      "Test date range: 2025-07-22 to 2025-09-30\n",
      "\n",
      "Available columns: ['order_number', 'order_created_date', 'order_created_time', 'requested_delivery_date', 'customer_number', 'product_code', 'order_qty', 'plant', 'storage_location', 'picking_picked_qty']\n",
      "\n",
      "Sample of test orders:\n",
      "shape: (5, 10)\n",
      "┌────────────┬────────────┬────────────┬───────────┬───┬───────────┬───────┬───────────┬───────────┐\n",
      "│ order_numb ┆ order_crea ┆ order_crea ┆ requested ┆ … ┆ order_qty ┆ plant ┆ storage_l ┆ picking_p │\n",
      "│ er         ┆ ted_date   ┆ ted_time   ┆ _delivery ┆   ┆ ---       ┆ ---   ┆ ocation   ┆ icked_qty │\n",
      "│ ---        ┆ ---        ┆ ---        ┆ _date     ┆   ┆ f64       ┆ str   ┆ ---       ┆ ---       │\n",
      "│ i64        ┆ date       ┆ i64        ┆ ---       ┆   ┆           ┆       ┆ str       ┆ f64       │\n",
      "│            ┆            ┆            ┆ date      ┆   ┆           ┆       ┆           ┆           │\n",
      "╞════════════╪════════════╪════════════╪═══════════╪═══╪═══════════╪═══════╪═══════════╪═══════════╡\n",
      "│ 10554581   ┆ 2025-07-22 ┆ 94318      ┆ 2025-07-2 ┆ … ┆ 1.0       ┆ 1001  ┆ 2010      ┆ 1.0       │\n",
      "│            ┆            ┆            ┆ 9         ┆   ┆           ┆       ┆           ┆           │\n",
      "│ 10554276   ┆ 2025-07-22 ┆ 83242      ┆ 2025-08-0 ┆ … ┆ 2.0       ┆ 30588 ┆ 2012      ┆ 2.0       │\n",
      "│            ┆            ┆            ┆ 1         ┆   ┆           ┆       ┆           ┆           │\n",
      "│ 10555476   ┆ 2025-07-22 ┆ 135737     ┆ 2025-07-2 ┆ … ┆ 1.0       ┆ 30588 ┆ 2012      ┆ 1.0       │\n",
      "│            ┆            ┆            ┆ 5         ┆   ┆           ┆       ┆           ┆           │\n",
      "│ 10556023   ┆ 2025-07-22 ┆ 163659     ┆ 2025-07-2 ┆ … ┆ 5.0       ┆ 30588 ┆ 2012      ┆ 5.0       │\n",
      "│            ┆            ┆            ┆ 4         ┆   ┆           ┆       ┆           ┆           │\n",
      "│ 10555456   ┆ 2025-07-22 ┆ 135120     ┆ 2025-07-2 ┆ … ┆ 2.0       ┆ 30588 ┆ 2012      ┆ 2.0       │\n",
      "│            ┆            ┆            ┆ 4         ┆   ┆           ┆       ┆           ┆           │\n",
      "└────────────┴────────────┴────────────┴───────────┴───┴───────────┴───────┴───────────┴───────────┘\n",
      "\n",
      "Predicting shortages for 1000 orders...\n",
      "✓ Predicted 29 shortages (2.9%)\n",
      "\n",
      "📊 Sample Predictions:\n",
      "shape: (10, 6)\n",
      "┌──────────────┬──────────────┬─────────────────┬───────────┬───────────────────┬──────────────────┐\n",
      "│ order_number ┆ product_code ┆ customer_number ┆ order_qty ┆ predicted_shortag ┆ shortage_probabi │\n",
      "│ ---          ┆ ---          ┆ ---             ┆ ---       ┆ e                 ┆ lity             │\n",
      "│ i64          ┆ str          ┆ i64             ┆ f64       ┆ ---               ┆ ---              │\n",
      "│              ┆              ┆                 ┆           ┆ i64               ┆ f32              │\n",
      "╞══════════════╪══════════════╪═════════════════╪═══════════╪═══════════════════╪══════════════════╡\n",
      "│ 10555437     ┆ 400242       ┆ 35354           ┆ 3.0       ┆ 1                 ┆ 0.999969         │\n",
      "│ 10555576     ┆ 413153       ┆ 30683           ┆ 1.0       ┆ 1                 ┆ 0.999958         │\n",
      "│ 10555304     ┆ 407009       ┆ 31157           ┆ 1.0       ┆ 1                 ┆ 0.999943         │\n",
      "│ 10555166     ┆ 400243       ┆ 33210           ┆ 10.0      ┆ 1                 ┆ 0.999918         │\n",
      "│ 10554654     ┆ 401416       ┆ 34337           ┆ 2.0       ┆ 1                 ┆ 0.999909         │\n",
      "│ 10555304     ┆ 416871       ┆ 31157           ┆ 1.0       ┆ 1                 ┆ 0.999862         │\n",
      "│ 10554250     ┆ 410854       ┆ 34123           ┆ 55.0      ┆ 1                 ┆ 0.999295         │\n",
      "│ 10555768     ┆ 403836       ┆ 32032           ┆ 12.8      ┆ 1                 ┆ 0.999161         │\n",
      "│ 10555328     ┆ 400933       ┆ 31157           ┆ 2.0       ┆ 1                 ┆ 0.994214         │\n",
      "│ 10554276     ┆ 400122       ┆ 32237           ┆ 2.0       ┆ 1                 ┆ 0.993006         │\n",
      "└──────────────┴──────────────┴─────────────────┴───────────┴───────────────────┴──────────────────┘\n",
      "\n",
      "⚠️  Found 18 high-risk orders (≥80% shortage probability)\n",
      "shape: (10, 6)\n",
      "┌──────────────┬──────────────┬─────────────────┬───────────┬───────────────────┬──────────────────┐\n",
      "│ order_number ┆ product_code ┆ customer_number ┆ order_qty ┆ predicted_shortag ┆ shortage_probabi │\n",
      "│ ---          ┆ ---          ┆ ---             ┆ ---       ┆ e                 ┆ lity             │\n",
      "│ i64          ┆ str          ┆ i64             ┆ f64       ┆ ---               ┆ ---              │\n",
      "│              ┆              ┆                 ┆           ┆ i64               ┆ f32              │\n",
      "╞══════════════╪══════════════╪═════════════════╪═══════════╪═══════════════════╪══════════════════╡\n",
      "│ 10555437     ┆ 400242       ┆ 35354           ┆ 3.0       ┆ 1                 ┆ 0.999969         │\n",
      "│ 10555576     ┆ 413153       ┆ 30683           ┆ 1.0       ┆ 1                 ┆ 0.999958         │\n",
      "│ 10555304     ┆ 407009       ┆ 31157           ┆ 1.0       ┆ 1                 ┆ 0.999943         │\n",
      "│ 10555166     ┆ 400243       ┆ 33210           ┆ 10.0      ┆ 1                 ┆ 0.999918         │\n",
      "│ 10554654     ┆ 401416       ┆ 34337           ┆ 2.0       ┆ 1                 ┆ 0.999909         │\n",
      "│ 10555304     ┆ 416871       ┆ 31157           ┆ 1.0       ┆ 1                 ┆ 0.999862         │\n",
      "│ 10554250     ┆ 410854       ┆ 34123           ┆ 55.0      ┆ 1                 ┆ 0.999295         │\n",
      "│ 10555768     ┆ 403836       ┆ 32032           ┆ 12.8      ┆ 1                 ┆ 0.999161         │\n",
      "│ 10555328     ┆ 400933       ┆ 31157           ┆ 2.0       ┆ 1                 ┆ 0.994214         │\n",
      "│ 10554276     ┆ 400122       ┆ 32237           ┆ 2.0       ┆ 1                 ┆ 0.993006         │\n",
      "└──────────────┴──────────────┴─────────────────┴───────────┴───────────────────┴──────────────────┘\n",
      "\n",
      "================================================================================\n",
      "DETAILED EXPLANATION FOR HIGHEST RISK ORDER\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "SHORTAGE RISK EXPLANATION\n",
      "============================================================\n",
      "\n",
      "Order: 10555437\n",
      "Product: 400242\n",
      "Customer: 35354\n",
      "Shortage Probability: 100.0%\n",
      "\n",
      "Top Risk Factors:\n",
      "   1. product_order_count..................... 916.0000\n",
      "   2. customer_total_order_qty................ 2740.4500\n",
      "   3. customer_product_shortage_rate.......... 1.0000\n",
      "   4. picking_picked_qty...................... 2.9600\n",
      "   5. order_qty............................... 3.0000\n",
      "   6. customer_order_count.................... 54.0000\n",
      "   7. order_day_of_month...................... 22.0000\n",
      "   8. product_order_qty_std................... 5.5590\n",
      "   9. order_month............................. 7.0000\n",
      "  10. product_avg_order_qty................... 6.5621\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Predict on New Orders (Fixed)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXAMPLE: PREDICTING ON NEW ORDERS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get the columns available in df_test\n",
    "print(\"Available columns in df_test:\")\n",
    "print(df_test.columns)\n",
    "\n",
    "# We need to use the original df_features to get all columns\n",
    "# Filter to the test date range\n",
    "test_start_date = df_test['order_created_date'].min()\n",
    "test_end_date = df_test['order_created_date'].max()\n",
    "\n",
    "print(f\"\\nTest date range: {test_start_date} to {test_end_date}\")\n",
    "\n",
    "# Get test orders from original df_features\n",
    "df_test_orders_full = df_features.filter(\n",
    "    (pl.col('order_created_date') >= test_start_date) &\n",
    "    (pl.col('order_created_date') <= test_end_date)\n",
    ").head(1000)  # Sample 1000 orders\n",
    "\n",
    "# Select the columns we need for prediction\n",
    "required_cols = [\n",
    "    'order_number', 'order_created_date', 'order_created_time', \n",
    "    'requested_delivery_date', 'customer_number', 'product_code', \n",
    "    'order_qty', 'plant', 'storage_location', 'picking_picked_qty'\n",
    "]\n",
    "\n",
    "# Check which columns exist\n",
    "available_cols = [col for col in required_cols if col in df_test_orders_full.columns]\n",
    "print(f\"\\nAvailable columns: {available_cols}\")\n",
    "\n",
    "df_test_orders = df_test_orders_full.select(available_cols)\n",
    "\n",
    "print(f\"\\nSample of test orders:\")\n",
    "print(df_test_orders.head())\n",
    "\n",
    "# Predict\n",
    "predictions = predictor.predict(df_test_orders)\n",
    "\n",
    "# Show results\n",
    "print(\"\\n📊 Sample Predictions:\")\n",
    "result_cols = ['order_number', 'product_code', 'customer_number', 'order_qty',\n",
    "               'predicted_shortage', 'shortage_probability']\n",
    "available_result_cols = [col for col in result_cols if col in predictions.columns]\n",
    "\n",
    "print(predictions.select(available_result_cols).sort('shortage_probability', descending=True).head(10))\n",
    "\n",
    "# Get high-risk orders\n",
    "high_risk = predictor.get_high_risk_orders(predictions, threshold=0.8)\n",
    "print(f\"\\n⚠️  Found {high_risk.height} high-risk orders (≥80% shortage probability)\")\n",
    "\n",
    "if high_risk.height > 0:\n",
    "    print(high_risk.select(available_result_cols).head(10))\n",
    "    \n",
    "    # Explain a specific prediction\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DETAILED EXPLANATION FOR HIGHEST RISK ORDER\")\n",
    "    print(\"=\"*80)\n",
    "    predictor.explain_prediction(high_risk.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a28df9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
